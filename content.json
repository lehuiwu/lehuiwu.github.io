{"meta":{"title":"Be kind,Be useful","subtitle":"勿忘初心，放得始终","description":null,"author":"PreCon","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"损失函数","slug":"损失函数cs231n","date":"2018-04-25T04:17:15.640Z","updated":"2018-04-25T06:38:55.195Z","comments":true,"path":"2018/04/25/损失函数cs231n/","link":"","permalink":"http://yoursite.com/2018/04/25/损失函数cs231n/","excerpt":"本内容为学习斯坦福课程CS231n 2017的课后笔记记录","text":"本内容为学习斯坦福课程CS231n 2017的课后笔记记录斯坦福cs231n课程笔记 损失函数 &emsp;&emsp;S:是通过分类器预测出来的类的分数。Si:指为对应i类的分数。Syi:代表了训练集的第i个样本的真实分类的分数。 &emsp;&emsp;为啥选择加上参数1：&emsp;&emsp;这其实在一定程度上是一个任意的选择，这实际上就是一个出现在损失函数中的常数，但实际上证明这是一个可以任意选择的值，因为我们并不真正关心损失函数中分数的绝对值，我们只担心这些分数的相对差值，我们只需要正确分类的分数，要远远大于不正确分类的分数，所以实际上如果你把你的整个W参数，放大或者缩小，那么所有的分数都会相应地放大或者缩小。这里选择1并不重要，这个自由参数1会消失，在这种放缩过程中消失，就像对于整个参数W的放缩一样。 Q1:如果汽车分数改变了，损失函数变化如何？&emsp;&emsp;答案就是如果汽车图像的分数发生了轻微的变化，那么损失函数将不会变化，SVM损失函数，记住，只关注于正确的分数比不正确的分数大过1，但是在这种情况下，汽车的分数比其他的都要大，所以如果汽车的分数改变了，只是稍微改变了一丢丢，那么1的界限依然奏效，损失函数并不会改变，我们依然得到为0的损失函数。 Q2:损失函数的最大值和最小值会是多少？&emsp;&emsp;答案：损失函数的最大值为无穷大，最小值为零。 Q3:当你初始化这些参数（W）并且从头开始训练，通常你先使用一些很小的随机值来，初始化W，你的分数的结果，在训练的初期倾向于呈现较小的均匀分布的值，并且问题在于如果你所有的S，也就是你所有的分数都近乎为0，并且差不多相等，那么当你使用多分类SVM时，损失函数预计会是如何？&emsp;&emsp;答案：分类的数量减去1。因为如果我们对所有不正确的类别遍历了一遍，那么实际上我们遍历了C-1个类别，在这些类别中的每一个，这两个分数差不多相同，所以我们就会得到一个值为1的损失项，因为存在着1的边界，我们将会得到C-1，这个结论实际上是有用的因为，这是一个有用的调试策略，当你使用这些方法的时候，当你开始训练的时候，你应该想到你的预期的损失函数应该是多达，如果在刚开始训练的时候你的损失函数，在第一次迭代的时候损失函数并不等于C-1，如果这样的话，着意味着你的程序可能有一个BUG，你得去检查一下，这是一个有用的结论。 Q4：如果我们将对于SVM的所有错误的分数求和会发生什么，如果我们将所有正确的分数求和会发生什么？&emsp;&emsp;答案：损失函数增加1。同时我们在实际应用中这么做的原因在于，通常损失函数为0的时候说明算法很好，所以你没有损失什么，这就很好了，所以我觉得你们的答案不会改变，你就不会再去寻求同样的分类器了，如果实际上你求和遍历了所有的类别，但是如果我们疏忽了正确的类别，那么我们的最小损失函数为0。 Q5:如果我们使用平均值，而不是求和呢？&emsp;&emsp;答案：不会改变，所以分类的数量需要提前确定，当我们选择数据集的时候，因为这只是将整个损失函数缩小了一个倍数，所以这并没有什么影响，任何缩放的操作，都不会有什么影响，因为我们实际上并不在意真正的分数值，或者是损失函数的真实值。 Q6:如果我们改变损失函数的公式，在max上加上一个平方项呢？这会成为另一个不同的分类算法么？&emsp;&emsp;答案：是不同的。所以这里的想法在于我们用一种非线性的方法，改变了在好和坏之间的权衡，所以实际上我们计算了另一种损失函数，关于合页损失函数的平方项的想法有时候，确实会在实际中应用，这是另一个技巧，当你针对你自己的问题，构成你自己的损失函数的时候。 Q7:为啥用平方项损失函数而不是非平方项的损失函数？&emsp;&emsp;答案：问题在于你考虑使用一个平方项损失函数而不是非平方项的损失函数，一个损失函数的全部意义在于量化不同的错误到底有多坏，同时分类器会犯不同的错误，我们如何对分类器可能犯的不同类型的错误进行权衡，如果你使用平方项损失函数，这意味着一个非常非常不好的错误，会更加不好，成平方地不好，那就真的很不好，我们并不想要任何被严重分错的结果，如果你使用合页损失函数，我们对于微小的错误并不在意，但是如果分类出现很多错误，出现很多错误，如果一个样例中出现了很多的错误，那么我们就扩大错误，以此来减小这个错误，这样就像对于仅仅有微小错误的例子，扩大错误，以此来纠正，所以这是一个优点波浪，但是这个使用线性函数与平方地思想，是量化我们关心多少的一种方法，关于不同类别的错误。 E.g. Suppose that we found a W such that L = 0. Is this W unique ?&emsp;&emsp;答案：No! 2W is also has L=0!，特别是因为我们谈了一点点，关于把整个问题扩大或缩小的事情，取决于W，你可以拿W乘以二，这个两倍的W，也将实现零损失。如果你拿W 我们加倍W，正确与不正确的安全边际值，也会翻倍，所以如果所有这些安全边际，都大于1，结果我们就对其翻倍，其值也会大于1，结果损失函数值依然为0。&emsp;&emsp;例子如下图所示： 正则项惩罚 E.g.分类器是如何从这些都是0值得损失函数之间，做出选择呢？&emsp;&emsp;那是因为我们在这里所做的，只是在数据方面的损失，我们仅仅是告诉分类器，他需要尝试找到，可以拟合训练集的W，但是实际上，我们并不关心这很多关于拟合训练数据，机器学习的重点是我们使用训练数据来找到一些分类器，然后我们将这个东西应用于测试数据，所以我们并不关心训练集的表现，我们真正关心的是这个分类器的测试数据的效果，所以如果我们只需要告诉分类器，拟合训练集的话，就可能导致我们陷入尴尬的境地，你会发现，分类器可能会行为反常，所以这是一个典型的例子。 假设我们有这样的数据，就是图中的蓝点，并且我们将会为训练数据拟合一些曲线，那么如果我们告诉分类器做的惟一的事情，是尝试和适合的训练数据，它可能会进入并具有非常曲折的曲线，并尝试完美分类所有的训练数据点，但这很糟糕，因为我们实际上并不关心这个表现，我们关心测试数据的性能，所以现在如果我们有新的数据进来，这种趋势也是如此，那么这个蓝色的虚线将是完全错误的，事实上，我们可能会喜欢的是，分类器可能是预测的这条绿色的直线，而不是这个复杂的蓝色的曲线，完全适合所有的训练数据，这在机器学习里是一个非常核心的基础性问题，实际上我们解决它用正则化的概念。 &emsp;&emsp;正则化项，鼓励模型以某种方式，选择更简单的W，这里的简单取决于任务的规模和模型的种类。这里实际上也体现了奥卡姆剃刀的理念，也是科学发现最基本的思想就是要让一个理论的应用更广泛，也就是说，如果你有许多个可以解释你观察结果的假设，一般来讲你应该选择最简约的，因为这样在未来可将其用于解释新的观察结果，我们运用这种直觉的方式，基于这一思想并运用于机器学习中，我们会直接假设正则化惩罚项，这通常记为R。 Q8: λ，R，W三项之间有什么相互作用？&emsp;&emsp;答案：实际上这主要是为了让这个弯弯的曲线成为一条值值的绿线，你可以想像，也许你正在做一个回归问题，根据不同的多项式基函数，如果你加入这个回归惩罚项，也许模型确实非常逼近高幂次多项式函数，但是通过加入这个回归项，如果和数据拟合的很好，或者相对好，你就可以让模型的幂次数降低，所以你可以想像有两种方法可以做到这一点，一种是限制你的模型，这个模型在于不要更高的阶数或模型太过复杂，另一种就是，加入这个软性惩罚项，这样一来，模型依然可以逼近复杂模型的效果，比如像这个例子中的高幂次多项式，如果你想使用这些更复杂的模型，你需要克服这个惩罚，使用它们的复杂性，这就是这个关系，不太线性的分类。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/categories/深度学习/"}],"tags":[{"name":"cs231n","slug":"cs231n","permalink":"http://yoursite.com/tags/cs231n/"}]},{"title":"图像分类 *线性分类I*","slug":"图像分类笔记cs231n2","date":"2018-04-25T02:59:25.301Z","updated":"2018-04-25T03:39:53.281Z","comments":true,"path":"2018/04/25/图像分类笔记cs231n2/","link":"","permalink":"http://yoursite.com/2018/04/25/图像分类笔记cs231n2/","excerpt":"本内容为学习斯坦福课程CS231n 2017的课后笔记记录","text":"本内容为学习斯坦福课程CS231n 2017的课后笔记记录斯坦福cs231n课程笔记 线性分类器线性分类可以解释为：&emsp;&emsp;每个种类的学习模板，看左下角的图，对图里的每个像素以及10个分类离得每一项，矩阵W里都有一些对应的项，告诉我们那个像素对那个分类有多少的影响，也就是说矩阵W里的每一行，都对应一个分类模板，如果我们解开这些行的值（成图片的大小），那么每一行又分别对应一些权重，每个图像像素值和对应的那个类别的一些权重，将这行分解回图像的大小，我们就可以可视化学到每个类的模板。&emsp;&emsp;对于线性分类器的另一种解释是：学习像素在高维空间的一个线性决策边界，其中高维空间就对应了图片能娶到的像素密度值。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/categories/深度学习/"}],"tags":[{"name":"cs231n","slug":"cs231n","permalink":"http://yoursite.com/tags/cs231n/"}]},{"title":"Ubuntu16.04 caffe配置 matlab接口","slug":"Ubuntu16.04编译caffe matlab接口","date":"2018-04-23T02:36:23.269Z","updated":"2018-04-23T02:45:10.814Z","comments":true,"path":"2018/04/23/Ubuntu16.04编译caffe matlab接口/","link":"","permalink":"http://yoursite.com/2018/04/23/Ubuntu16.04编译caffe matlab接口/","excerpt":"本篇为在上一篇Ubuntu16.04配置好caffe GPU版的基础上，编译caffe的matlab接口介绍","text":"本篇为在上一篇Ubuntu16.04配置好caffe GPU版的基础上，编译caffe的matlab接口介绍 编译caffe的matlab接口（1）修改caffe-master/Makefile.config&emsp;&emsp;这一步主要是在Caffe的编译配置文件Makefile.config中加入Matlab的路径。注意路径文件夹是要包含Matlab安装目录的“bin”文件夹的。 （2）编译接口。这里默认已经编译好了Caffe源码主体部分。所以直接编译接口。在caffe-master目录下打开终端，输入： make matcaffe 至于如何编译Caffe源码的主体部分请大家百度，就是make all ,make test那些。我是一开始没有在Makefile.config中加入Matlab路径，所以编译Caffe主体代码时不会编译Matlab接口。（3）测试接口。输入 make mattest&emsp;&emsp;这里可能报错：caffe_.mexa64: undefined symbol: _ZN2cv8imencodeERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKNS_11_InputArrayERSt6vectorIhSaIhEERKSB_IiSaIiEE PS：只替换库libstdc++.so.6是不行的，要解决此问题需要多替换几个库。输入终端命令： 1 export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4:/usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4:/usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4:/usr/lib/x86_64-linux-gnu/libstdc++.so.6:/usr/lib/x86_64-linux-gnu/libfreetype.so.6 2 export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/ 注意：目录/usr/lib/x86_64-linux-gnu/是我的系统库目录。大家可以通过查询库所在位置来确定自己的系统库目录： sudo find / -name libstdc++.so.6重新运行make mattest ， 问题解决～ 下面是我另外碰到的一些问题：① MEX-file ‘/home/zhangjiqing/caffe/matlab/+caffe/private/caffe_.meax64’无效：/home/zhangjiqing/caffe/matlab/+caffe/private/caffe_.mexa64:undefined symbol:_ZN2cv8imencodeERKNSt7_cxx1112basic_stringSt11char_traitslcESalcEEERKNS_1alhEERKSB_liSaliEE解决方法如下： ②运行make mattest时可能会碰到下面这个错误：MEX-file ‘/home/a204/caffe/matlab/+caffe/private/caffe_.meax64’无效：/usr/local/MATLAB/R2015b/bin/glnxa64/../../sys/os/glnxa64/libstdc++.so.6:version GLIBCXX_3.4.20not found(required by /home/a204/caffe/matlab/+caffe/private/caffe_.mexa64)解决方式是将matlab的libstdc++.so.6链接到系统的库文件。 sudo rm /usr/local/MATLAB/R2015b/sys/os/glnxa64/libstdc++.so.6 sudo ln -s /usr/lib/x86_64-linux-gnu/libstdc++.so.6 /usr/local/MATLAB/R2015b/sys/os/glnxa64/libstdc++.so.6 这样可以解决，不过主要在使用rm命令式需要谨慎，先备份。 （4）在Matlab中试试接口 下载bvlc_reference_caffenet.caffemodel链接：http://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel 下载好之后放入文件夹/caffe-master/models/bvlc_reference_caffenet 这是因为一会运行的demo要使用这个模型。 在终端输入命令“matlab”(打不开的自己去添加PATH)打开Matlab，切换到目录/caffe-master/matlab/demo/（这很重要） 输入命令 run(‘classification_demo.m’) 或者双击打开classification_demo.m直接点击上面控制台上的“运行”即可，不需要输入参数。 输出是一个1000×1的矩阵，因为ImageNet数据集有1000个类别。 到此OK，大家加油～","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/categories/深度学习/"}],"tags":[{"name":"caffe matlab","slug":"caffe-matlab","permalink":"http://yoursite.com/tags/caffe-matlab/"}]},{"title":"Ubuntu16.04 caffe配置 GPU","slug":"Ubuntu16.04配置caffe+GPU+CUDA+CUDNN","date":"2018-04-18T05:08:40.654Z","updated":"2018-04-23T02:42:42.537Z","comments":true,"path":"2018/04/18/Ubuntu16.04配置caffe+GPU+CUDA+CUDNN/","link":"","permalink":"http://yoursite.com/2018/04/18/Ubuntu16.04配置caffe+GPU+CUDA+CUDNN/","excerpt":"Ubuntu16.04 安装配置Caffe GPU+cuda+Cudnncaffe第二次安装配置，以前仅配置的是CPU所以不用安装cuda+cudnn，现在配置GPU版本的，踩的坑比较多，同时由于被其他事打扰，所以无法专心配置，现在特地写一博客，解决配置过程以及踩过的坑如何解决！！！！","text":"Ubuntu16.04 安装配置Caffe GPU+cuda+Cudnncaffe第二次安装配置，以前仅配置的是CPU所以不用安装cuda+cudnn，现在配置GPU版本的，踩的坑比较多，同时由于被其他事打扰，所以无法专心配置，现在特地写一博客，解决配置过程以及踩过的坑如何解决！！！！caffe配置： Ubuntu16.04+GPU+cuda8.0+cudnn5.1安装过程 安装相关依赖项sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler sudo apt-get install --no-install-recommends libboost-all-dev sudo apt-get install libopenblas-dev liblapack-dev libatlas-base-dev sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev 安装NVIDA驱动注意ubuntu16.04可以利用软件驱动更新装载显卡驱动不需要以下的操作，可以直接在终端输入： sudo nvidia-smi，若列出了如下GPU的信息列表则表示驱动安装成功，不用进行下面的配置操作。 （1）查询NVIDIA驱动&emsp;&emsp;首先去官网&emsp;http://www.nvidia.com/Download/index.aspx?lang=en-us&emsp;查看适合自己的显卡驱动并下载：驱动文件后缀名应当是以.run结尾的。 输入显卡型号显卡驱动搜索结果（2）安装驱动在终端下输入：sudo gedit /etc/modprobe.d/blacklist.conf输入密码后在最后一行加上blacklist nouveau，这是将Ubuntu自带的显卡驱动加入黑名单。在终端输入：sudo update-initramfs -u重启电脑~这里要尤其注意，安装显卡驱动要先切换到文字界面，(按Ctrl+Alt+F1~F6).所以，启动电脑后，先进入文字界面。然后，输入命令sudo service lightdm stop现在可以安装驱动了，先进入家目录cd ~，然后：sudo ./NVIDIA-Linux-x86_64-375.20.run，按照提示一步步来~。完成后，再次重启电脑。安装完成之后输入以下指令进行验证：sudo nvidia-smi，若列出了GPU的信息列表则表示驱动安装成功。如下图： 安装CUDACUDA是NVIDIA的编程语言平台，想使用GPU就必须要使用cuda。（1）下载CUDA首先在官网上https://developer.nvidia.com/cuda-downloads下载CUDA： （2）下载后完成执行一下命令： 1 sudo chmod 777 cuda_8.0.61_375.26_linux.run 2 sudo ./cuda_8.0.61_375.26_linux.run 注意 cuda_8.0.44_linux.run 需对应自己下载的版本执行后会有一系列提示让你确认，但是注意，有个让你选择是否安装nvidia367驱动时，一定要选择否：Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 367.48?因为前面我们已经安装了更加新的nvidia367，所以这里不要选择安装。其余的都直接默认或者选择是即可。（3）环境变量配置打开~/.bashrc文件：sudo gedit ~/.bashrc将以下内容写入~/.bashrc尾部： export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}} export LD_LIBRARY_PATH=/usr/local/cuda8.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} （4）测试CUDA的samples 1 cd /usr/local/cuda-8.0/samples/1_Utilities/deviceQuery 2 make 3 sudo ./deviceQuery 如果显示一些关于GPU的信息，则说明安装成功。 配置cuDNNcuDNN是GPU加速计算深层神经网络的库。首先去官网https://developer.nvidia.com/rdp/cudnn-download下载cuDNN，需要注册一个账号才能下载。下载版本号如下图： 下载cuDNN5.1之后进行解压：（对应自己下载的版本）sudo tar -zxvf ./cudnn-8.0-linux-x64-v5.1.tgz进入cuDNN5.1解压之后的include目录,在命令行进行如下操作： cd cuda /include sudo cp cudnn.h /usr/local/cuda/include #复制头文件 再将进入lib64目录下的动态文件进行复制和链接： cd .. cd lib64 sudo cp lib* /usr/local/cuda/lib64/ #复制动态链接库 cd /usr/local/cuda/lib64/ sudo rm -rf libcudnn.so libcudnn.so.5 #删除原有动态文件 sudo ln -s libcudnn.so.5.0.5 libcudnn.so.5 #生成软衔接 sudo ln -s libcudnn.so.5 libcudnn.so #生成软链接 画重点此处sudo ln -s libcudnn.so.5.0.5 libcudnn.so.5中的libcudnn.so.5.0.5文件需要与你电脑中/usr/local/cuda/lib64/文件夹中的对应，如果不对应就会在编译caffe时make all 报如下错误：（原因是cudnn链接没有弄好） 错误如： LD -O .build_release/lib/libcaffe.so.1.0.0 /usr/bin/ld:找不到 -lcudnn collect2: error: ld returned 1 exit status Makefile:573:recipe for target &apos;.build_release/lib/libcaffe.so.1.0.0&apos; failed Make: *** [.build_release/lib/libcaffe.so.1.0.0] Error1 例如本人/usr/local/cuda/lib64/文件夹对应的文件为： 所以sudo ln -s libcudnn.so.5.0.5 libcudnn.so.5需要改为sudo ln -s libcudnn.so.5.0.10 libcudnn.so.5，否则会报错，谷歌百度，上都没有答案，仅此一家！ 安装opencv 3.1从官网http://opencv.org/downloads.html下载Opencv,并将其解压到你要安装的位置，假设解压到了/home/opencv。 1 unzip opencv-3.1.0.zip 2 sudo cp ./opencv-3.1.0 /home 3 sudo mv opencv-3.1.0 opencv 安装前准备，创建编译文件夹： cd ~/opencv mkdir build cd build 配置： 1 sudo apt install cmake 2 sudo cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local .. 编译： sudo make -j8 -j8表示并行计算，根据自己电脑的配置进行设置，配置比较低的电脑可以将数字改小或不使用，直接输make。 可能出现问题： 这是因为opecv3.0与cuda8.0不兼容导致的。解决办法：修改 ～/opencv/modules/cudalegacy/src/graphcuts.cpp文件内容，如图： 其中，#if !defined (HAVE_CUDA) || defined (CUDA_DISABLER)||(CUDART_VERSION&gt;=8000)是我们修改的。以上只是将opencv编译成功，还没将opencv安装，需要运行下面指令进行安装： sudo make install 配置caffe(1) 使用Git直接下载Caffe非常简单，或者去https://github.com/BVLC/caffe下载。由于我习惯去github上找代码，所以就直接去下载的源码。下载完成后，会在家目录下的下载里找到caffe-master.zip，用unzip命令解压到家目录下，然后重命名为caffe.(2) 因为make指令只能make Makefile.config文件，而Makefile.config.example是caffe给出的makefile例子，因此，首先将Makefile.config.example的内容复制到Makefile.config： sudo cp Makefile.config.example Makefile.config (3) 打开并修改配置文件：sudo gedit Makefile.config #打开Makefile.config文件 根据个人情况修改文件：a.若使用cudnn，则将#USE_CUDNN := 1修改成：USE_CUDNN := 1;b.若使用的opencv版本是3的，则将#OPENCV_VERSION := 3修改为：OPENCV_VERSION :=3;c.若要使用python来编写layer，则将#WITH_PYTHON_LAYER := 1 修改为 WITH_PYTHON_LAYER := 1;d.重要的一项 :将 # Whatever else you find you need goes here. 下面的 1 INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include 2 LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib 修改为： 1 INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial 2 LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial 这是因为ubuntu16.04的文件包含位置发生了变化，尤其是需要用到的hdf5的位置，所以需要更改这一路径。（4）修改makefile文件打开makefile文件，做如下修改：将： NVCCFLAGS +=-ccbin=$(CXX) -Xcompiler-fPIC $(COMMON_FLAGS) 替换为： NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS) (5) 编辑/usr/local/cuda/include/host_config.h 将其中的第115行（或119行）注释掉：将 #error-- unsupported GNU version! gcc versions later than 4.9 are not supported! 改为 //#error-- unsupported GNU version! gcc versions later than 4.9 are not supported! (6) 编译make all -j8 #-j根据自己电脑配置决定 编译过程中可能会出现如下错误：错误内容1：”fatal error: hdf5.h: 没有那个文件或目录”解决办法：step1: 在Makefile.config文件的第85行，添加/usr/include/hdf5/serial/ 到 INCLUDE_DIRS，也就是把下面第一行代码改为第二行代码。将： INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include 替换为： INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial/ stept2: 在Makefile文件的第173行，把 hdf5_hl 和hdf5修改为hdf5_serial_hl 和 hdf5_serial，也就是把下面第一行代码改为第二行代码。将： LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_hl hdf5 改为： LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_serial_hl hdf5_serial 错误内容2：“libcudnn.so.5 cannot open shared object file: No such file or directory”解决办法是将一些文件复制到/usr/local/lib文件夹下：注意自己CUDA的版本号！ 1 sudo cp /usr/local/cuda-8.0/lib64/libcudart.so.8.0 /usr/local/lib/libcudart.so.8.0 &amp;&amp; sudo ldconfig 2 sudo cp /usr/local/cuda-8.0/lib64/libcublas.so.8.0 /usr/local/lib/libcublas.so.8.0 &amp;&amp; sudo ldconfig 3 sudo cp /usr/local/cuda-8.0/lib64/libcurand.so.8.0 /usr/local/lib/libcurand.so.8.0 &amp;&amp; sudo ldconfig 4 sudo cp /usr/local/cuda-8.0/lib64/libcudnn.so.5 /usr/local/lib/libcudnn.so.5 &amp;&amp; sudo ldconfig （8）测试 make test make runtest 如果运行之后出现下图，说明caffe配置成功。 到此caffe配置完毕！ MNIST数据集测试配置caffe完成后，我们可以利用MNIST数据集对caffe进行测试，过程如下：1.将终端定位到Caffe根目录cd ~/caffe 2.下载MNIST数据库并解压缩./data/mnist/get_mnist.sh 3.将其转换成Lmdb数据库格式./examples/mnist/create_mnist.sh 4.训练网络./examples/mnist/train_lenet.sh训练的时候可以看到损失与精度数值，如下图： 到此OK，大家加油～","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/categories/深度学习/"}],"tags":[{"name":"caffe","slug":"caffe","permalink":"http://yoursite.com/tags/caffe/"}]},{"title":"图像分类 *K-最近邻算法*","slug":"图像分类笔记cs231n1","date":"2018-04-09T04:49:26.541Z","updated":"2018-04-25T03:41:21.512Z","comments":true,"path":"2018/04/09/图像分类笔记cs231n1/","link":"","permalink":"http://yoursite.com/2018/04/09/图像分类笔记cs231n1/","excerpt":"图像分类笔记 本内容为学习斯坦福课程CS231n 2017的课后笔记记录","text":"图像分类笔记 本内容为学习斯坦福课程CS231n 2017的课后笔记记录 原文链接地址：https://blog.csdn.net/nnnnnnnnnnnny/article/details/54577123&emsp;&emsp;例子：以上图为例，图像分类模型读取该图片，并生成该图片属于集合 {cat, dog, hat, mug}中各个标签的概率。需要注意的是，对于计算机来说，图像是一个由数字组成的巨大的3维数组。在这个例子中，猫的图像大小是宽248像素，高400像素，有3个颜色通道，分别是红、绿和蓝（简称RGB）。如此，该图像就包含了248X400X3=297600个数字，每个数字都是在范围0-255之间的整型，其中0表示全黑，255表示全白。我们的任务就是把这些上百万的数字变成一个简单的标签，比如“猫”。 &emsp;&emsp;图像分类的任务，就是对于一个给定的图像，预测它属于的那个分类标签（或者给出属于一系列不同标签的可能性）。图像是3维数组，数组元素是取值范围从0到255的整数。数组的尺寸是宽度x高度x3，其中这个3代表的是红、绿和蓝3个颜色通道。困难和挑战：对于人来说，识别出一个像“猫”一样视觉概念是简单至极的，然而从计算机视觉算法的角度来看就值得深思了。我们在下面列举了计算机视觉算法在图像识别方面遇到的一些困难，要记住图像是以3维数组来表示的，数组中的元素是亮度值。&emsp;&emsp;•视角变化（Viewpoint variation）：同一个物体，摄像机可以从多个角度来展现。&emsp;&emsp;•大小变化（Scale variation）：物体可视的大小通常是会变化的（不仅是在图片中，在真实世界中大小也是变化的）。&emsp;&emsp;•形变（Deformation）：很多东西的形状并非一成不变，会有很大变化。&emsp;&emsp;•遮挡（Occlusion）：目标物体可能被挡住。有时候只有物体的一小部分（可以小到几个像素）是可见的。&emsp;&emsp;光照条件（Illumination conditions）：在像素层面上，光照的影响非常大。&emsp;&emsp;背景干扰（Background clutter）：物体可能混入背景之中，使之难以被辨认。&emsp;&emsp;类内差异（Intra-class variation）：一类物体的个体之间的外形差异很大，比如椅子。这一类物体有许多不同的对象，每个都有自己的外形。&emsp;&emsp;面对以上所有变化及其组合，好的图像分类模型能够在维持分类结论稳定的同时，保持对类间差异足够敏感。 数据驱动方法：&emsp;&emsp;如何写一个图像分类的算法呢？这和写个排序算法可是大不一样。怎么写一个从图像中认出猫的算法？搞不清楚。因此，与其在代码中直接写明各类物体到底看起来是什么样的，倒不如说我们采取的方法和教小孩儿看图识物类似：给计算机很多数据，然后实现学习算法，让计算机学习到每个类的外形。这种方法，就是数据驱动方法。既然该方法的第一步就是收集已经做好分类标注的图片来作为训练集，那么下面就看看数据库到底长什么样： &emsp;&emsp;一个有4个视觉分类的训练集。在实际中，我们可能有上千的分类，每个分类都有成千上万的图像。 图像分类流程：&emsp;&emsp;在课程视频中已经学习过，图像分类就是输入一个元素为像素值的数组，然后给它分配一个分类标签。完整流程如下：&emsp;&emsp;•输入：输入是包含N个图像的集合，每个图像的标签是K种分类标签中的一种。这个集合称为训练集。&emsp;&emsp;•学习： 这一步的任务是使用训练集来学习每个类到底长什么样。一般该步骤叫做训练分类器或者学习一个模型。&emsp;&emsp;•评价：让分类器来预测它未曾见过的图像的分类标签，并以此来评价分类器的质量。我们会把分类器预测的标签和图像真正的分类标签对比。毫无疑问，分类器预测的分类标签和图像真正的分类标签如果一致，那就是好事，这样的情况越多越好。 Nearest Neighbor分类器作为课程介绍的第一个方法，我们来实现一个Nearest Neighbor分类器。虽然这个分类器和卷积神经网络没有任何关系，实际中也极少使用，但通过实现它，可以让读者对于解决图像分类问题的方法有个基本的认识。图像分类数据集：CIFAR-10。一个非常流行的图像分类数据集是CIFAR-10。这个数据集包含了60000张32X32的小图像。每张图像都有10种分类标签中的一种。这60000张图像被分为包含50000张图像的训练集和包含10000张图像的测试集。在下图中你可以看见10个类的10张随机图片。 左边：从CIFAR-10数据库来的样本图像。右边：第一列是测试图像，然后第一列的每个测试图像右边是使用Nearest Neighbor算法，根据像素差异，从训练集中选出的10张最类似的图片。&emsp;&emsp;假设现在我们有CIFAR-10的50000张图片（每种分类5000张）作为训练集，我们希望将余下的10000作为测试集并给他们打上标签。Nearest Neighbor算法将会拿着测试图片和训练集中每一张图片去比较，然后将它认为最相似的那个训练集图片的标签赋给这张测试图片。上面右边的图片就展示了这样的结果。请注意上面10个分类中，只有3个是准确的。比如第8行中，马头被分类为一个红色的跑车，原因在于红色跑车的黑色背景非常强烈，所以这匹马就被错误分类为跑车了。&emsp;&emsp;那么具体如何比较两张图片呢？在本例中，就是比较32x32x3的像素块。最简单的方法就是逐个像素比较，最后将差异值全部加起来。换句话说，就是将两张图片先转化为两个向量I1和I2，然后计算他们的 L1距离： 这里的求和是针对所有的像素。下面是整个比较流程的图例： 以图片中的一个颜色通道为例来进行说明。两张图片使用L1距离来进行比较。逐个像素求差值，然后将所有差值加起来得到一个数值。如果两张图片一模一样，那么L1距离为0，但是如果两张图片很是不同，那L1值将会非常大。 距离选择：计算向量间的距离有很多种方法，另一个常用的方法是L2距离，从几何学的角度，可以理解为它在计算两个向量间的欧式距离。L2距离的公式如下： ! 换句话说，我们依旧是在计算像素间的差值，只是先求其平方，然后把这些平方全部加起来，最后对这个和开方。L1和L2比较:比较这两个度量方式是挺有意思的。在面对两个向量之间的差异时，L2比L1更加不能容忍这些差异。也就是说，相对于1个巨大的差异，L2距离更倾向于接受多个中等程度的差异。L1和L2都是在p-norm常用的特殊形式。 k-Nearest Neighbor分类器你可能注意到了，为什么只用最相似的1张图片的标签来作为测试图像的标签呢？这不是很奇怪吗！是的，使用k-Nearest Neighbor分类器就能做得更好。它的思想很简单：与其只找最相近的那1个图片的标签，我们找最相似的k个图片的标签，然后让他们针对测试图片进行投票，最后把票数最高的标签作为对测试图片的预测。所以当k=1的时候，k-Nearest Neighbor分类器就是Nearest Neighbor分类器。从直观感受上就可以看到，更高的k值可以让分类的效果更平滑，使得分类器对于异常值更有抵抗力。 用于超参数调优的验证集k-NN分类器需要设定k值，那么选择哪个k值最合适的呢？我们可以选择不同的距离函数，比如L1范数和L2范数等，那么选哪个好？还有不少选择我们甚至连考虑都没有考虑到（比如：点积）。所有这些选择，被称为超参数（hyperparameter）。在基于数据进行学习的机器学习算法设计中，超参数是很常见的。一般说来，这些超参数具体怎么设置或取值并不是显而易见的。 你可能会建议尝试不同的值，看哪个值表现最好就选哪个。好主意！我们就是这么做的，但这样做的时候要非常细心。特别注意：决不能使用测试集来进行调优。当你在设计机器学习算法的时候，应该把测试集看做非常珍贵的资源，不到最后一步，绝不使用它。如果你使用测试集来调优，而且算法看起来效果不错，那么真正的危险在于：算法实际部署后，性能可能会远低于预期。这种情况，称之为算法对测试集过拟合。从另一个角度来说，如果使用测试集来调优，实际上就是把测试集当做训练集，由测试集训练出来的算法再跑测试集，自然性能看起来会很好。这其实是过于乐观了，实际部署起来效果就会差很多。所以，最终测试的时候再使用测试集，可以很好地近似度量你所设计的分类器的泛化性能（在接下来的课程中会有很多关于泛化性能的讨论）。 测试数据集只使用一次，即在训练完成后评价最终的模型时使用。 好在我们有不用测试集调优的方法。其思路是：从训练集中取出一部分数据用来调优，我们称之为验证集（validation set）。以CIFAR-10为例，我们可以用49000个图像作为训练集，用1000个图像作为验证集。验证集其实就是作为假的测试集来调优。 程序结束后，我们会作图分析出哪个k值表现最好，然后用这个k值来跑真正的测试集，并作出对算法的评价。 把训练集分成训练集和验证集。使用验证集来对所有超参数调优。最后只在测试集上跑一次并报告结果。 超参数调优注意问题 1.选择能对你训练集给出最高准确率，表现最佳的超参数&emsp;&emsp;千万不要这么做&emsp;&emsp;例如在之前的k-最近邻分类算法中，假设k=1我们总能完美分类训练集数据，所以如果我们采用这一策略，总是选择k=1，但是正如之前案例所见的，在实践中，让k取更大的值会在训练集中分错个别数据，但是对于在训练集中，未出现过的数据分类性能更佳。&emsp;&emsp;我们关心的不是要尽可能拟合训练集，而是要让我们的分类器，我们的方法在训练集以外的未知数据上表现更好。 2.把所有的数据分成两部分，一部分是训练集，一部分是测试集，然后在训练集上用不同的超参数来训练算法，然后将训练好的分类器，用在测试集上，再选择一组在测试集上表现最好的超参数。&emsp;&emsp;错误做法&emsp;&emsp;因为同样的机器学习系统的目的，是让我们了解算法表现究竟如何，所以测试集的目的是给了我们一种预估的方法，即在没有遇到的数据上算法表现将会如何，如果采用这种用不同的超参数，训练不同算法的策略，然后选择在测试集上表现最好的超参数，那么很可能我们选择了，一组超参数，只是让我们的算法在这组测试集上表现良好，但是这组测试集的表现无法代表在全新的未见过的数据上的表现。 3.更常见的做法就是将数据，分为不同的三组，大部分数据作为训练集（train set），然后建立一个验证集（validation set），一个测试集（test set），我们通常所做的就是，在训练集上用不同的超参数来训练算法，在验证集上进行评估，然后用一组超参数，选择在验证集上表现最好的，然后当完成了这些步骤以后，你也完成了所有的调试，所有都完成了，然后把这组在验证集上表现最佳的分类器拿出来，在测试集上跑一跑，这才是你写到论文中的数据，也是你要写到报告中的数据，这个数据才告诉你，你的算法在未见的新数据上表现如何，非常非常重要的一点就是，必须分割验证集和测试集，要保证测试集收到严格的控制。 4.超参数的另一个方法就是交叉验证，这个在小数据集中更常用一些，在深度学习中不那么常用。因为：在深度学习中，当我们训练大型模型时，训练本身非常消耗计算能力，因此这些方法实际不常用。 5.训练集和验证集的区别：&emsp;&emsp;如果你想一想k-最近邻分类算法（KNN），那么训练集就是一堆贴上标签的图片，我们记下标签，要给图像分类，我们会将图片与训练集的每一个元素比较，然后将与训练点最接近点的标签作为结果，我们的算法会记住训练集中的所有样本，然后我们会把验证集中的每个元素与训练集中的每个元素比较，将它为依据判定分类器的准确率，在验证集上表现如何，这就是验证集和训练集的区别，你的算法可以看到训练集中的各个标签，但是在验证集中，你的算法不能直接看到他们的标签，我们只是用验证集中的标签，来检查我们算法的表现。 6.关于测试集能不能很好地代表真实世界中的数据？&emsp;&emsp;我们背后的统计学假设就是，你的数据都互相独立，服从同一分布，这样你数据上所有的点都来自同一个概率分布，当然在现实中不可能总是这样的情况，你可能碰到一些其他的情况，也就是你的测试集代表性，不佳，不能很好地反映真实世界。这一问题就是数据集的创建者和数据集管理者需要好好思考的。 交叉验证：&emsp;&emsp;有时候，训练集数量较小（因此验证集的数量更小），人们会使用一种被称为交叉验证的方法，这种方法更加复杂些。还是用刚才的例子，如果是交叉验证集，我们就不是取1000个图像，而是将训练集平均分成5份，其中4份用来训练，1份用来验证。然后我们循环着取其中4份来训练，其中1份来验证，最后取所有5次验证结果的平均值作为算法验证结果。 实际应用。在实际情况下，人们不是很喜欢用交叉验证，主要是因为它会耗费较多的计算资源。一般直接把训练集按照50%-90%的比例分成训练集和验证集。但这也是根据具体情况来定的：如果超参数数量多，你可能就想用更大的验证集，而验证集的数量不够，那么最好还是用交叉验证吧。至于分成几份比较好，一般都是分成3、5和10份。 常用的数据分割模式。给出训练集和测试集后，训练集一般会被均分。这里是分成5份。前面4份用来训练，黄色那份用作验证集调优。如果采取交叉验证，那就各份轮流作为验证集。最后模型训练完毕，超参数都定好了，让模型跑一次（而且只跑一次）测试集，以此测试结果评价算法。 Nearest Neighbor分类器的优劣现在对Nearest Neighbor分类器的优缺点进行思考。首先，Nearest Neighbor分类器易于理解，实现简单。其次，算法的训练不需要花时间，因为其训练过程只是将训练集数据存储起来。然而测试要花费大量时间计算，因为每个测试图像需要和所有存储的训练图像进行比较，这显然是一个缺点。在实际应用中，我们关注测试效率远远高于训练效率。其实，我们后续要学习的卷积神经网络在这个权衡上走到了另一个极端：虽然训练花费很多时间，但是一旦训练完成，对新的测试数据进行分类非常快。这样的模式就符合实际使用需求。 Nearest Neighbor分类器的计算复杂度研究是一个活跃的研究领域，若干Approximate Nearest Neighbor (ANN)算法和库的使用可以提升Nearest Neighbor分类器在数据上的计算速度（比如：FLANN）。这些算法可以在准确率和时空复杂度之间进行权衡，并通常依赖一个预处理/索引过程，这个过程中一般包含kd树的创建和k-means算法的运用。 Nearest Neighbor分类器在某些特定情况（比如数据维度较低）下，可能是不错的选择。但是在实际的图像分类工作中，很少使用。因为图像都是高维度数据（他们通常包含很多像素），而高维度向量之间的距离通常是反直觉的。下面的图片展示了基于像素的相似和基于感官的相似是有很大不同的： 在高维度数据上，基于像素的的距离和感官上的非常不同。上图中，右边3张图片和左边第1张原始图片的L2距离是一样的。很显然，基于像素比较的相似和感官上以及语义上的相似是不同的。 这里还有个视觉化证据，可以证明使用像素差异来比较图像是不够的。z这是一个叫做t-SNE的可视化技术，它将CIFAR-10中的图片按照二维方式排布，这样能很好展示图片之间的像素差异值。在这张图片中，排列相邻的图片L2距离就小。 上图使用t-SNE的可视化技术将CIFAR-10的图片进行了二维排列。排列相近的图片L2距离小。可以看出，图片的排列是被背景主导而不是图片语义内容本身主导。 具体说来，这些图片的排布更像是一种颜色分布函数，或者说是基于背景的，而不是图片的语义主体。比如，狗的图片可能和青蛙的图片非常接近，这是因为两张图片都是白色背景。从理想效果上来说，我们肯定是希望同类的图片能够聚集在一起，而不被背景或其他不相关因素干扰。为了达到这个目的，我们不能止步于原始像素比较，得继续前进。 小结：实际应用k-NN如果你希望将k-NN分类器用到实处（最好别用到图像上，若是仅仅作为练手还可以接受），那么可以按照以下流程：&emsp;&emsp;1.预处理你的数据：对你数据中的特征进行归一化（normalize），让其具有零平均值（zero mean）和单位方差（unit variance）。在后面的小节我们会讨论这些细节。本小节不讨论，是因为图像中的像素都是同质的，不会表现出较大的差异分布，也就不需要标准化处理了。&emsp;&emsp;2.如果数据是高维数据，考虑使用降维方法，比如PCA(wiki ref, CS229ref, blog ref)或随机投影。&emsp;&emsp;3.将数据随机分入训练集和验证集。按照一般规律，70%-90% 数据作为训练集。这个比例根据算法中有多少超参数，以及这些超参数对于算法的预期影响来决定。如果需要预测的超参数很多，那么就应该使用更大的验证集来有效地估计它们。如果担心验证集数量不够，那么就尝试交叉验证方法。如果计算资源足够，使用交叉验证总是更加安全的（份数越多，效果越好，也更耗费计算资源）。&emsp;&emsp;4.在验证集上调优，尝试足够多的k值，尝试L1和L2两种范数计算方式。&emsp;&emsp;5.如果分类器跑得太慢 ，尝试使用Approximate Nearest Neighbor库（比如FLANN）来加速这个过程，其代价是降低一些准确率。&emsp;&emsp;6.对最优的超参数做记录。记录最优参数后，是否应该让使用最优参数的算法在完整的训练集上运行并再次训练呢？因为如果把验证集重新放回到训练集中（自然训练集的数据量就又变大了），有可能最优参数又会有所变化。在实践中，不要这样做。千万不要在最终的分类器中使用验证集数据，这样做会破坏对于最优参数的估计。直接使用测试集来测试用最优参数设置好的最优模型，得到测试集数据的分类准确率，并以此作为你的kNN分类器在该数据上的性能表现。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/categories/深度学习/"}],"tags":[{"name":"cs231n","slug":"cs231n","permalink":"http://yoursite.com/tags/cs231n/"}]}]}