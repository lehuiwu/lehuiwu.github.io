<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Be kind,Be useful</title>
  
  <subtitle>勿忘初心，放得始终</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-04-27T08:25:35.252Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>PreCon</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>损失函数和优化（Loss Functions）</title>
    <link href="http://yoursite.com/2018/04/25/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96(Loss%20Functions)/"/>
    <id>http://yoursite.com/2018/04/25/损失函数和优化(Loss Functions)/</id>
    <published>2018-04-25T04:17:15.640Z</published>
    <updated>2018-04-27T08:25:35.252Z</updated>
    
    <content type="html"><![CDATA[<p><strong>本内容为学习斯坦福课程CS231n 2017的课后笔记记录</strong><br><a id="more"></a><br><strong>斯坦福cs231n课程笔记 <em>损失函数</em></strong>  </p><p><div align="center"><img src="https://i.imgur.com/LQ2zKQ3.png" alt=""><div align="left">  </div></div></p><p><div align="center"><img src="https://i.imgur.com/2aUuyfY.png" alt=""><div align="left">  </div></div></p><p><div align="center"><img src="https://i.imgur.com/WxLrcfP.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/4MmxrBA.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/Up1Ilch.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/sn3i4cC.png" alt=""><div align="left"><br>&emsp;&emsp;S:是通过分类器预测出来的类的分数。Si:指为对应i类的分数。Syi:代表了训练集的第i个样本的真实分类的分数。  </div></div></p><p><div align="center"><img src="https://i.imgur.com/vy9rkwq.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/QnVuchs.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/P9SgR96.png" alt=""><div align="left"><br>&emsp;&emsp;<strong>为啥选择加上参数1：</strong><br>&emsp;&emsp;这其实在一定程度上是一个任意的选择，这实际上就是一个出现在损失函数中的常数，但实际上证明这是一个可以任意选择的值，因为我们并不真正关心损失函数中分数的绝对值，我们只担心这些分数的相对差值，我们只需要正确分类的分数，要远远大于不正确分类的分数，所以实际上如果你把你的整个W参数，放大或者缩小，那么所有的分数都会相应地放大或者缩小。这里选择1并不重要，这个自由参数1会消失，在这种放缩过程中消失，就像对于整个参数W的放缩一样。  </div></div></p><p><div align="center"><img src="https://i.imgur.com/HwTPr3e.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/x7KoSN0.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/9RbhqKy.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/XPypKDj.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/DiPXzHM.png" alt=""><div align="left"><br><strong>Q1:如果汽车分数改变了，损失函数变化如何？</strong><br>&emsp;&emsp;答案就是如果汽车图像的分数发生了轻微的变化，那么损失函数将不会变化，SVM损失函数，记住，只关注于正确的分数比不正确的分数大过1，但是在这种情况下，汽车的分数比其他的都要大，所以如果汽车的分数改变了，只是稍微改变了一丢丢，那么1的界限依然奏效，损失函数并不会改变，我们依然得到为0的损失函数。</div></div></p><p><div align="center"><img src="https://i.imgur.com/I32HAO7.png" alt=""><div align="left"><br><strong>Q2:损失函数的最大值和最小值会是多少？</strong><br>&emsp;&emsp;答案：损失函数的最大值为无穷大，最小值为零。</div></div></p><p><div align="center"><img src="https://i.imgur.com/vKk0Y3P.png" alt=""><div align="left"><br><strong>Q3:当你初始化这些参数（W）并且从头开始训练，通常你先使用一些很小的随机值来，初始化W，你的分数的结果，在训练的初期倾向于呈现较小的均匀分布的值，并且问题在于如果你所有的S，也就是你所有的分数都近乎为0，并且差不多相等，那么当你使用多分类SVM时，损失函数预计会是如何？</strong><br>&emsp;&emsp;答案：分类的数量减去1。因为如果我们对所有不正确的类别遍历了一遍，那么实际上我们遍历了C-1个类别，在这些类别中的每一个，这两个分数差不多相同，所以我们就会得到一个值为1的损失项，因为存在着1的边界，我们将会得到C-1，这个结论实际上是有用的因为，这是一个有用的调试策略，当你使用这些方法的时候，当你开始训练的时候，你应该想到你的预期的损失函数应该是多达，如果在刚开始训练的时候你的损失函数，在第一次迭代的时候损失函数并不等于C-1，如果这样的话，着意味着你的程序可能有一个BUG，你得去检查一下，这是一个有用的结论。</div></div></p><p><div align="center"><img src="https://i.imgur.com/PWFPOF3.png" alt=""><div align="left"><br><strong>Q4：如果我们将对于SVM的所有错误的分数求和会发生什么，如果我们将所有正确的分数求和会发生什么？</strong><br>&emsp;&emsp;答案：损失函数增加1。同时我们在实际应用中这么做的原因在于，通常损失函数为0的时候说明算法很好，所以你没有损失什么，这就很好了，所以我觉得你们的答案不会改变，你就不会再去寻求同样的分类器了，如果实际上你求和遍历了所有的类别，但是如果我们疏忽了正确的类别，那么我们的最小损失函数为0。  </div></div></p><p><div align="center"><img src="https://i.imgur.com/mhhaCqy.png" alt=""><div align="left"><br><strong>Q5:如果我们使用平均值，而不是求和呢？</strong><br>&emsp;&emsp;答案：不会改变，所以分类的数量需要提前确定，当我们选择数据集的时候，因为这只是将整个损失函数缩小了一个倍数，所以这并没有什么影响，任何缩放的操作，都不会有什么影响，因为我们实际上并不在意真正的分数值，或者是损失函数的真实值。  </div></div></p><p><div align="center"><img src="https://i.imgur.com/eOEBT4j.png" alt=""><div align="left"><br><strong>Q6:如果我们改变损失函数的公式，在max上加上一个平方项呢？这会成为另一个不同的分类算法么？</strong><br>&emsp;&emsp;答案：是不同的。所以这里的想法在于我们用一种非线性的方法，改变了在好和坏之间的权衡，所以实际上我们计算了另一种损失函数，关于合页损失函数的平方项的想法有时候，确实会在实际中应用，这是另一个技巧，当你针对你自己的问题，构成你自己的损失函数的时候。</div></div></p><p><strong>Q7:为啥用平方项损失函数而不是非平方项的损失函数？</strong><br>&emsp;&emsp;答案：问题在于你考虑使用一个平方项损失函数而不是非平方项的损失函数，一个损失函数的全部意义在于量化不同的错误到底有多坏，同时分类器会犯不同的错误，我们如何对分类器可能犯的不同类型的错误进行权衡，如果你使用平方项损失函数，这意味着一个非常非常不好的错误，会更加不好，成平方地不好，那就真的很不好，我们并不想要任何被严重分错的结果，如果你使用合页损失函数，我们对于微小的错误并不在意，但是如果分类出现很多错误，出现很多错误，如果一个样例中出现了很多的错误，那么我们就扩大错误，以此来减小这个错误，这样就像对于仅仅有微小错误的例子，扩大错误，以此来纠正，所以这是一个优点波浪，但是这个使用线性函数与平方地思想，是量化我们关心多少的一种方法，关于不同类别的错误。</p><p><div align="center"><img src="https://i.imgur.com/Jnql7VE.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/jAHbSGn.png" alt=""><div align="left"><br><strong>E.g. Suppose that we found a W such that L = 0. Is this W unique ?</strong><br>&emsp;&emsp;答案：No! 2W is also has L=0!，特别是因为我们谈了一点点，关于把整个问题扩大或缩小的事情，取决于W，你可以拿W乘以二，这个两倍的W，也将实现零损失。如果你拿W 我们加倍W，正确与不正确的安全边际值，也会翻倍，所以如果所有这些安全边际，都大于1，结果我们就对其翻倍，其值也会大于1，结果损失函数值依然为0。<br>&emsp;&emsp;例子如下图所示：  </div></div></p><p><div align="center"><img src="https://i.imgur.com/MzPcTxB.png" alt=""><div align="left"></div></div></p><h2 id="正则项惩罚"><a href="#正则项惩罚" class="headerlink" title="正则项惩罚"></a>正则项惩罚</h2><p><div align="center"><img src="https://i.imgur.com/6efsk2c.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/4wdAGJ5.png" alt=""><div align="left"><br><strong>E.g.分类器是如何从这些都是0值得损失函数之间，做出选择呢？</strong><br>&emsp;&emsp;那是因为我们在这里所做的，只是在数据方面的损失，我们仅仅是告诉分类器，他需要尝试找到，可以拟合训练集的W，但是实际上，我们并不关心这很多关于拟合训练数据，机器学习的重点是我们使用训练数据来找到一些分类器，然后我们将这个东西应用于测试数据，所以我们并不关心训练集的表现，我们真正关心的是这个分类器的测试数据的效果，所以如果我们只需要告诉分类器，拟合训练集的话，就可能导致我们陷入尴尬的境地，你会发现，分类器可能会行为反常，所以这是一个典型的例子。  </div></div></p><p><div align="center"><img src="https://i.imgur.com/fwAO4xE.png" alt=""><div align="left"><br><strong>假设我们有这样的数据，就是图中的蓝点，并且我们将会为训练数据拟合一些曲线，那么如果我们告诉分类器做的惟一的事情，是尝试和适合的训练数据，它可能会进入并具有非常曲折的曲线，并尝试完美分类所有的训练数据点，但这很糟糕，因为我们实际上并不关心这个表现，我们关心测试数据的性能，所以现在如果我们有新的数据进来，这种趋势也是如此，那么这个蓝色的虚线将是完全错误的，事实上，我们可能会喜欢的是，分类器可能是预测的这条绿色的直线，而不是这个复杂的蓝色的曲线，完全适合所有的训练数据，这在机器学习里是一个非常核心的基础性问题，实际上我们解决它用正则化的概念。</strong>  </div></div></p><p><div align="center"><img src="https://i.imgur.com/3N9KZan.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/B01PzS5.png" alt=""><div align="left"><br>&emsp;&emsp;<strong>正则化项，鼓励模型以某种方式，选择更简单的W，这里的简单取决于任务的规模和模型的种类。这里实际上也体现了奥卡姆剃刀的理念，也是科学发现最基本的思想就是要让一个理论的应用更广泛，也就是说，如果你有许多个可以解释你观察结果的假设，一般来讲你应该选择最简约的，因为这样在未来可将其用于解释新的观察结果，我们运用这种直觉的方式，基于这一思想并运用于机器学习中，我们会直接假设正则化惩罚项，这通常记为R。</strong></div></div></p><p><div align="center"><img src="https://i.imgur.com/TqVGoos.png" alt=""><div align="left"><br><strong>Q1: λ，R，W三项之间有什么相互作用？</strong><br>&emsp;&emsp;答案：实际上这主要是为了让这个弯弯的曲线成为一条值值的绿线，你可以想像，也许你正在做一个回归问题，根据不同的多项式基函数，如果你加入这个回归惩罚项，也许模型确实非常逼近高幂次多项式函数，但是通过加入这个回归项，如果和数据拟合的很好，或者相对好，你就可以让模型的幂次数降低，所以你可以想像有两种方法可以做到这一点，一种是限制你的模型，这个模型在于不要更高的阶数或模型太过复杂，另一种就是，加入这个软性惩罚项，这样一来，模型依然可以逼近复杂模型的效果，比如像这个例子中的高幂次多项式，如果你想使用这些更复杂的模型，你需要克服这个惩罚，使用它们的复杂性，这就是这个关系，不太线性的分类。<br>&emsp;&emsp;实际上有很多不同类型的正则项，最常见的可能是L2正则项，但是还有很多你可能会看到的，这个L2正则项就是欧氏范数，其理念实际上是对权值向量的欧氏范数进行惩罚。有时候也会看到L1的正则项，是对权值向量的L1范数进行惩罚,将W中所有元素的值加和。L1正则项具有一些很好的性质，例如可以让矩阵W变得稀疏。还有就是弹性网络正则化，这是L1和L2的组合。还有max norm正则化，惩罚的max norm不是L1或者L2范数。这些正则化是你看到的不仅仅是应用在深度学习，同时也在机器学习的的很多领域，甚至更广泛地进行优化都有应用。在后面的课程中，也会看到一些更具体的正则化类型，例如Dropout，batch normalization。正则化的主要作用是为了减轻模型的复杂度，而不是去试图拟合数据。  </div></div></p><p><div align="center"><img src="https://i.imgur.com/p0Kaxyu.png" alt=""><div align="left"><br>&emsp;&emsp;其中，N是训练集的数据量。现在正则化惩罚添加到了损失函数里面，并用超参数\lambda来计算其权重。该超参数无法简单确定，需要通过交叉验证来获取。</div></div></p><p><div align="center"><img src="https://i.imgur.com/pRlO7Gw.png" alt=""><div align="left"><br>&emsp;&emsp;这里有一些训练样本x，有两个不同的W正在考虑，这里x是一个包含四个1的4维向量。对于w我们来考虑两种不同的可能性。第一种情形是W的第一个元素是1，另外三个元素都是0，另外一种情形是W的全部元素都是0.25。当进行线性分类的时候，我们真正讨论的是x与W的点积结果，这时候两种情形的W其实都是一样的，因为和x点积的结果是一样的。现在可以考虑一下那种情形下加入L2后的线性回归模型会更好。当然是每个元素都是0.25的W的会更好，因为它具有较小的范数。在线性分类器中，W所反映的是x向量的值在多大程度上对输出有影响，所以L2正则化的作用是，它更加能传递出x中不同元素值的影响，它的robust可能会更好，更多的考虑了W的整体分布，令所有的元素具有较小的复杂度。L1正则化则具有完全相反的解释，当使用L1正则化的时候，我们更倾向于第一个元素为1，其他为0的W，L1正则化对复杂度具有不同的概念，即那个模型可能有较小的复杂度，在权值向量中，用数字0来描述模型的复杂度，L1更加喜欢稀疏解，倾向让大部分W的元素接近于0。如何度量复杂度是视不同问题而定，针对模型和数据。</div></div></p><p><div align="center"><img src="https://i.imgur.com/oyWU6c6.png" alt=""><div align="left"><br><strong>正则化的宏观理念就是：你对你模型做的任何事情，也就是种种所谓的惩罚，主要目的是为了减轻模型的复杂度，而不是去试图，拟合数据。</strong><br>&emsp;&emsp;需要注意的是，和权重不同，偏差没有这样的效果，因为它们并不控制输入维度上的影响强度。因此通常只对权重W正则化，而不正则化偏差b。在实际操作中，可发现这一操作的影响可忽略不计。最后，因为正则化惩罚的存在，不可能在所有的例子中得到0的损失值，这是因为只有当W=0的特殊情况下，才能得到损失值为0。<br>&emsp;&emsp;另外一个非常流行的选择是除了多类别SVM损失函数之外,深度学习中另外一个常用的选择是多项逻辑回归或者叫softmax。这个损失函数在深度学习中使用得更为广泛。当我们进行分类时，模型函数F输出了10个数字，这些数字代表了这些类别的得分，在多类型SVM中我们并没有针对类别的得分作出解释，我们只是希望正确分类的分数要比不正确分类的分数要高才好。但是对于softmax函数，我们将赋予这些分数一些额外的含义，并且会利用这些按分数针对我们的类别去计算概率分布。在这个函数中我们将其指数化令到结果都为正，然后用将指数求和来进行归一化，所以分数经过softmax函数处理后就可以得到概率分布。对所有的类别都有了对应的在0-1之间的概率，所有类别的概率和为1。我们将得到的概率值与目标值进行比较。如果真实的类别是喵，目标的概率分布就应把所有的概率击中到喵上，所以喵的概率是1而其他类别是0。我们现在要做的事情是将softmax计算的结果去匹配上述的目标概率分布。这里我们的损失函数就是正确类别概率的对数再取负值，我们希望概率接近1。同时log函数式一个单调函数，当针对正确类别的最大化 logP ，意味着想要它变高，但是损失函数式用来度量不好的程度，所以对其取负值将求最大值变为求最小值。  </div></div></p><p><div align="center"><img src="https://i.imgur.com/dVrDmkW.png" alt=""><div align="left"><br>在Softmax分类器中，函数映射:  </div></div></p><p><div align="center"><img src="https://i.imgur.com/UevpOeU.png" alt=""><div align="left"><br>保持不变，但将这些评分值视为每个分类的未归一化的对数概率，并且将折叶损失（hinge loss）替换为交叉熵损失（cross-entropy loss）。公式如下：  </div></div></p><p><div align="center"><img src="https://i.imgur.com/31PTdQm.png" alt=""><div align="left"><br>在上式中，使用f_ j来表示分类评分向量f中的第j个元素。和之前一样，整个数据集的损失值是数据集中所有样本数据的损失值L_i的均值与正则化损失R(W)之和。其中函数:  </div></div></p><p><div align="center"><img src="https://i.imgur.com/RgzM3kd.png" alt=""><div align="left"><br>被称作softmax函数：其输入值是一个向量，向量中元素为任意实数的评分值（z中的），函数对其进行压缩，输出一个向量，其中每个元素值在0到1之间，且所有元素之和为1。所以，包含softmax函数的完整交叉熵损失看起唬人，实际上还是比较容易理解的。<br><strong>信息理论视角：</strong>在“真实”分布p和估计分布q之间的交叉熵定义如下：  </div></div></p><p><div align="center"><img src="https://i.imgur.com/mwPRlbd.png" alt=""><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"></div></div></p><p><div align="center"><div align="left"><br><strong>内容到此，大家加油</strong></div></div></p>]]></content>
    
    <summary type="html">
    
      线性分类器
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>图像分类 *线性分类I*</title>
    <link href="http://yoursite.com/2018/04/25/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%AC%94%E8%AE%B0cs231n2/"/>
    <id>http://yoursite.com/2018/04/25/图像分类笔记cs231n2/</id>
    <published>2018-04-25T02:59:25.301Z</published>
    <updated>2018-04-25T07:17:43.610Z</updated>
    
    <content type="html"><![CDATA[<p><strong>本内容为学习斯坦福课程CS231n 2017的课后笔记记录</strong><br><a id="more"></a><br><strong>斯坦福cs231n课程笔记 <em>线性分类器</em></strong><br><strong>线性分类可以解释为：</strong><br>&emsp;&emsp;每个种类的学习模板，看左下角的图，对图里的每个像素以及10个分类离得每一项，矩阵W里都有一些对应的项，告诉我们那个像素对那个分类有多少的影响，也就是说矩阵W里的每一行，都对应一个分类模板，如果我们解开这些行的值（成图片的大小），那么每一行又分别对应一些权重，每个图像像素值和对应的那个类别的一些权重，将这行分解回图像的大小，我们就可以可视化学到每个类的模板。<br>&emsp;&emsp;对于线性分类器的另一种解释是：学习像素在高维空间的一个线性决策边界，其中高维空间就对应了图片能娶到的像素密度值。  </p><p><div align="center"><img src="https://i.imgur.com/KghACsR.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/I5BvkY2.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/JojcF8t.png" alt=""><div align="left"><br>&emsp;&emsp;<strong>概述：</strong>我们将要实现一种更强大的方法来解决图像分类问题，该方法可以自然地延伸到神经网络和卷积神经网络上。这种方法主要有两部分组成：一个是评分函数（score function），它是原始图像数据到类别分值的映射。另一个是损失函数（loss function），它是用来量化预测分类标签的得分与真实标签之间一致性的。该方法可转化为一个最优化问题，在最优化过程中，将通过更新评分函数的参数来最小化损失函数值。  </div></div></p><p><div align="center"><img src="https://i.imgur.com/NFJOgEi.png" alt=""><div align="left"><br><strong>从图像到标签分值的参数化映射:</strong><br>&emsp;&emsp;该方法的第一部分就是定义一个评分函数，这个函数将图像的像素值映射为各个分类类别的得分，得分高低代表图像属于该类别的可能性高低。下面会利用一个具体例子来展示该方法。现在假设有一个包含很多图像的训练集x_i∈R^D，每个图像都有一个对应的分类标签y_i。这里i=1,2…N并且y_i∈1…K。这就是说，我们有N个图像样例，每个图像的维度是D，共有K种不同的分类。<br>&emsp;&emsp;举例来说，在CIFAR-10中，我们有一个N=50000的训练集，每个图像有D=32x32x3=3072个像素，而K=10，这是因为图片被分为10个不同的类别（狗，猫，汽车等）。我们现在定义评分函数为：f:R^D →R^K，该函数是原始图像像素到分类分值的映射。</div></div></p><p><div align="center"><img src="https://i.imgur.com/F3oN8BT.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/xjUr9ID.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/7H0ZrQq.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/spaxT0a.png" alt=""><div align="left"><br><strong>线性分类器：</strong>在本模型中，我们从最简单的概率函数开始，一个线性映射：</div></div></p><p><div align="center"><img src="https://i.imgur.com/irt1GOF.png" alt=""><div align="left"><br>&emsp;&emsp;在上面的公式中，假设每个图像数据都被拉长为一个长度为D的列向量，大小为[D x 1]。其中大小为[K x D]的矩阵W和大小为[K x 1]列向量b为该函数的参数（parameters）。还是以CIFAR-10为例，Xi就包含了第i个图像的所有像素信息，这些信息被拉成为一个[3072 x 1]的列向量，W大小为[10x3072]，b的大小为[10x1]。因此，3072个数字（原始像素数值）输入函数，函数输出10个数字（不同分类得到的分值）。参数W被称为权重（weights）。b被称为偏差向量（bias vector），这是因为它影响输出数值，但是并不和原始数据x_i产生关联。在实际情况中，人们常常混用权重和参数这两个术语。<br><strong>需要注意的几点：</strong><br>&emsp;&emsp;首先，一个单独的矩阵乘法Wxi就高效地并行评估10个不同的分类器（每个分类器针对一个分类），其中每个类的分类器就是W的一个行向量。<br>注意我们认为输入数据(xi,yi)是给定且不可改变的，但参数W和b是可控制改变的。我们的目标就是通过设置这些参数，使得计算出来的分类分值情况和训练集中图像数据的真实类别标签相符。在接下来的课程中，我们将详细介绍如何做到这一点，但是目前只需要直观地让正确分类的分值比错误分类的分值高即可。<br>该方法的一个优势是训练数据是用来学习到参数W和b的，一旦训练完成，训练数据就可以丢弃，留下学习到的参数即可。这是因为一个测试图像可以简单地输入函数，并基于计算出的分类分值来进行分类。<br>&emsp;&emsp;最后，注意只需要做一个矩阵乘法和一个矩阵加法就能对一个测试数据分类，这比k-NN中将测试图像和所有训练数据做比较的方法快多了。</div></div></p><p><div align="center"><img src="https://i.imgur.com/Rhjew7X.png" alt=""><div align="left"><br><strong>理解线性分类器</strong><br>&emsp;&emsp;线性分类器计算图像中3个颜色通道中所有像素的值与权重的矩阵乘，从而得到分类分值。根据我们对权重设置的值，对于图像中的某些位置的某些颜色，函数表现出喜好或者厌恶（根据每个权重的符号而定）。举个例子，可以想象“船”分类就是被大量的蓝色所包围（对应的就是水）。那么“船”分类器在蓝色通道上的权重就有很多的正权重（它们的出现提高了“船”分类的分值），而在绿色和红色通道上的权重为负的就比较多（它们的出现降低了“船”分类的分值）。<br>&emsp;&emsp;一个将图像映射到分类分值的例子。为了便于可视化，假设图像只有4个像素（都是黑白像素，这里不考虑RGB通道），有3个分类（红色代表猫，绿色代表狗，蓝色代表船，注意，这里的红、绿和蓝3种颜色仅代表分类，和RGB通道没有关系）。首先将图像像素拉伸为一个列向量，与W进行矩阵乘，然后得到各个分类的分值。需要注意的是，这个W一点也不好：猫分类的分值非常低。从上图来看，算法倒是觉得这个图像是一只狗。</div></div></p><p><div align="center"><img src="https://i.imgur.com/LCE2YVf.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/FaqadLn.png" alt=""><div align="left"><br><strong>偏差和权重的合并技巧：</strong>在进一步学习前，要提一下这个经常使用的技巧。它能够将我们常用的参数W和b合二为一。回忆一下，分类评分函数定义为：  </div></div></p><p><div align="center"><img src="https://i.imgur.com/1YU0uYl.png" alt=""><div align="left"><br>分开处理这两个参数（权重参数W和偏差参数b）有点笨拙，一般常用的方法是把两个参数放到同一个矩阵中，同时Xi向量就要增加一个维度，这个维度的数值是常量1，这就是默认的偏差维度。这样新的公式就简化成下面这样：    </div></div></p><p><div align="center"><img src="https://i.imgur.com/ahw24cF.png" alt=""><div align="left"></div></div></p><p>还是以CIFAR-10为例，那么x_i的大小就变成[3073x1]，而不是[3072x1]了，多出了包含常量1的1个维度）。W大小就是[10x3073]了。W中多出来的这一列对应的就是偏差值b，具体见下图：  </p><p><div align="center"><img src="https://i.imgur.com/tcmDXMg.jpg" alt=""><div align="left"><br>偏差技巧的示意图。左边是先做矩阵乘法然后做加法，右边是将所有输入向量的维度增加1个含常量1的维度，并且在权重矩阵中增加一个偏差列，最后做一个矩阵乘法即可。左右是等价的。通过右边这样做，我们就只需要学习一个权重矩阵，而不用去学习两个分别装着权重和偏差的矩阵了。</div></div></p><p><div align="center"><img src="https://i.imgur.com/KSeRcLH.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/QwMPsp4.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/6pu1rpx.png" alt=""><div align="left"></div></div></p><p><div align="center"><img src="https://i.imgur.com/mzb9C3o.png" alt=""><div align="left"></div></div></p>]]></content>
    
    <summary type="html">
    
      线性分类器
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04 caffe配置 matlab接口</title>
    <link href="http://yoursite.com/2018/04/23/Ubuntu16.04%E7%BC%96%E8%AF%91caffe%20matlab%E6%8E%A5%E5%8F%A3/"/>
    <id>http://yoursite.com/2018/04/23/Ubuntu16.04编译caffe matlab接口/</id>
    <published>2018-04-23T02:36:23.269Z</published>
    <updated>2018-04-23T02:45:10.814Z</updated>
    
    <content type="html"><![CDATA[<p><strong>本篇为在上一篇Ubuntu16.04配置好caffe GPU版的基础上，编译caffe的matlab接口介绍</strong><br><a id="more"></a>  </p><h1 id="编译caffe的matlab接口"><a href="#编译caffe的matlab接口" class="headerlink" title="编译caffe的matlab接口"></a>编译caffe的matlab接口</h1><p>（1）修改caffe-master/Makefile.config<br>&emsp;&emsp;这一步主要是在Caffe的编译配置文件Makefile.config中加入Matlab的路径。注意路径文件夹是要包含Matlab安装目录的“bin”文件夹的。  </p><p><div align="center"><img src="https://i.imgur.com/nPewFF3.png" alt=""><div align="left"><br>（2）编译接口。这里默认已经编译好了Caffe源码主体部分。所以直接编译接口。在caffe-master目录下打开终端，输入：  make matcaffe   至于如何编译Caffe源码的主体部分请大家百度，就是make all ,make test那些。我是一开始没有在Makefile.config中加入Matlab路径，所以编译Caffe主体代码时不会编译Matlab接口。<br>（3）测试接口。输入 make mattest<br>&emsp;&emsp;这里可能报错：caffe_.mexa64: undefined symbol: _ZN2cv8imencodeERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKNS_11_InputArrayERSt6vectorIhSaIhEERKSB_IiSaIiEE  </div></div></p><p><div align="center"><img src="https://i.imgur.com/GSwrPr2.png" alt=""><div align="left"><br>PS：只替换库libstdc++.so.6是不行的，要解决此问题需要多替换几个库。输入终端命令：  </div></div></p><pre><code>1 export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4:/usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4:/usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4:/usr/lib/x86_64-linux-gnu/libstdc++.so.6:/usr/lib/x86_64-linux-gnu/libfreetype.so.62 export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/</code></pre><p><strong>注意：目录/usr/lib/x86_64-linux-gnu/是我的系统库目录。大家可以通过查询库所在位置来确定自己的系统库目录：</strong><br>    <code>sudo find / -name  libstdc++.so.6</code><br>重新运行make mattest ， 问题解决～  </p><p><div align="center"><img src="https://i.imgur.com/wb2hY1G.png" alt=""><div align="left"></div></div></p><p><strong>下面是我另外碰到的一些问题：</strong><br>① MEX-file ‘/home/zhangjiqing/caffe/matlab/+caffe/private/caffe_.meax64’无效：/home/zhangjiqing/caffe/matlab/+caffe/private/caffe_.mexa64:undefined symbol:_ZN2cv8imencodeERKNSt7_cxx1112basic_stringSt11char_traitslcESalcEEERKNS_1alhEERKSB_liSaliEE<br>解决方法如下：</p><p><div align="center"><img src="https://i.imgur.com/zRsQyxz.png" alt=""><div align="left"></div></div></p><p>②运行<code>make mattest</code>时可能会碰到下面这个错误：<br>MEX-file ‘/home/a204/caffe/matlab/+caffe/private/caffe_.meax64’无效：/usr/local/MATLAB/R2015b/bin/glnxa64/../../sys/os/glnxa64/libstdc++.so.6:version <code>GLIBCXX_3.4.20</code>not found(required by /home/a204/caffe/matlab/+caffe/private/caffe_.mexa64)解决方式是将matlab的libstdc++.so.6链接到系统的库文件。</p><pre><code>sudo rm /usr/local/MATLAB/R2015b/sys/os/glnxa64/libstdc++.so.6sudo ln -s /usr/lib/x86_64-linux-gnu/libstdc++.so.6 /usr/local/MATLAB/R2015b/sys/os/glnxa64/libstdc++.so.6</code></pre><p><strong>这样可以解决，不过主要在使用<code>rm</code>命令式需要谨慎，先备份。</strong></p><p>（4）在Matlab中试试接口  </p><p><1>下载bvlc_reference_caffenet.caffemodel<br>链接：<code>http://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel</code>  </1></p><p>下载好之后放入文件夹<code>/caffe-master/models/bvlc_reference_caffenet</code> 这是因为一会运行的demo要使用这个模型。  </p><p><2>在终端输入命令“matlab”(打不开的自己去添加PATH)打开Matlab，切换到目录/caffe-master/matlab/demo/（这很重要）  </2></p><p><3>输入命令 run(‘classification_demo.m’) 或者双击打开classification_demo.m直接点击上面控制台上的“运行”即可，不需要输入参数。  </3></p><p><4>输出是一个1000×1的矩阵，因为ImageNet数据集有1000个类别。</4></p><p><div align="center"><img src="https://i.imgur.com/1E8l7sx.png" alt=""><div align="left"><br><strong>到此OK，大家加油～</strong></div></div></p>]]></content>
    
    <summary type="html">
    
      caffe配置matlab接口
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="caffe matlab" scheme="http://yoursite.com/tags/caffe-matlab/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04 caffe配置 GPU</title>
    <link href="http://yoursite.com/2018/04/18/Ubuntu16.04%E9%85%8D%E7%BD%AEcaffe+GPU+CUDA+CUDNN/"/>
    <id>http://yoursite.com/2018/04/18/Ubuntu16.04配置caffe+GPU+CUDA+CUDNN/</id>
    <published>2018-04-18T05:08:40.654Z</published>
    <updated>2018-04-23T02:42:42.537Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Ubuntu16-04-安装配置Caffe-GPU-cuda-Cudnn"><a href="#Ubuntu16-04-安装配置Caffe-GPU-cuda-Cudnn" class="headerlink" title="Ubuntu16.04 安装配置Caffe GPU+cuda+Cudnn"></a>Ubuntu16.04 安装配置Caffe GPU+cuda+Cudnn</h1><p>caffe第二次安装配置，以前仅配置的是CPU所以不用安装cuda+cudnn，现在配置GPU版本的，踩的坑比较多，同时由于被其他事打扰，所以无法专心配置，现在特地写一博客，解决配置过程以及踩过的坑如何解决！！！！<br><a id="more"></a><br><strong>caffe配置：  Ubuntu16.04+GPU+cuda8.0+cudnn5.1</strong><br><strong>安装过程</strong></p><h2 id="安装相关依赖项"><a href="#安装相关依赖项" class="headerlink" title="安装相关依赖项"></a>安装相关依赖项</h2><pre><code>sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compilersudo apt-get install --no-install-recommends libboost-all-devsudo apt-get install libopenblas-dev liblapack-dev libatlas-base-devsudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev</code></pre><h2 id="安装NVIDA驱动"><a href="#安装NVIDA驱动" class="headerlink" title="安装NVIDA驱动"></a>安装NVIDA驱动</h2><p><strong>注意ubuntu16.04可以利用软件驱动更新装载显卡驱动不需要以下的操作，可以直接在终端输入：    <code>sudo nvidia-smi</code>，若列出了如下GPU的信息列表则表示驱动安装成功，不用进行下面的配置操作。</strong>  </p><p><div align="center"><img src="https://i.imgur.com/y9tp04K.png" alt=""><div align="left"></div></div></p><p>（1）查询NVIDIA驱动<br>&emsp;&emsp;首先去官网&emsp;<code>http://www.nvidia.com/Download/index.aspx?lang=en-us</code>&emsp;查看适合自己的显卡驱动并下载：驱动文件后缀名应当是以.run结尾的。</p><p><div align="center"><img src="https://i.imgur.com/hXVaagE.png" alt=""><br>输入显卡型号<br><img src="https://i.imgur.com/4M2Yb1n.png" alt=""><br>显卡驱动搜索结果<div align="left"><br>（2）安装驱动<br>在终端下输入：<code>sudo gedit /etc/modprobe.d/blacklist.conf</code><br>输入密码后在最后一行加上<code>blacklist nouveau</code>，这是将Ubuntu自带的显卡驱动加入黑名单。<br>在终端输入：<code>sudo update-initramfs -u</code><br>重启电脑~<br>这里要尤其注意，安装显卡驱动要先切换到文字界面，(按Ctrl+Alt+F1~F6).所以，启动电脑后，先进入文字界面。<br>然后，输入命令<code>sudo service lightdm stop</code><br>现在可以安装驱动了，先进入家目录<code>cd ~</code>，然后：<code>sudo ./NVIDIA-Linux-x86_64-375.20.run</code>，按照提示一步步来~。<br>完成后，再次重启电脑。<br>安装完成之后输入以下指令进行验证：<code>sudo nvidia-smi</code>，若列出了GPU的信息列表则表示驱动安装成功。如下图：</div></div></p><p><div align="center"><img src="https://i.imgur.com/mOtDp3w.png" alt=""><div align="left"></div></div></p><h2 id="安装CUDA"><a href="#安装CUDA" class="headerlink" title="安装CUDA"></a>安装CUDA</h2><p>CUDA是NVIDIA的编程语言平台，想使用GPU就必须要使用cuda。<br>（1）下载CUDA<br>首先在官网上<code>https://developer.nvidia.com/cuda-downloads</code>下载CUDA：  </p><p><div align="center"><img src="https://i.imgur.com/AIGOok6.png" alt=""><div align="left"><br>（2）下载后完成执行一下命令：  </div></div></p><pre><code>1 sudo chmod 777 cuda_8.0.61_375.26_linux.run  2 sudo ./cuda_8.0.61_375.26_linux.run  </code></pre><p><strong>注意 cuda_8.0.44_linux.run 需对应自己下载的版本</strong><br><strong>执行后会有一系列提示让你确认，但是注意，有个让你选择是否安装nvidia367驱动时，一定要选择否：<br><code>Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 367.48?</code><br>因为前面我们已经安装了更加新的nvidia367，所以这里不要选择安装。其余的都直接默认或者选择是即可。</strong><br>（3）环境变量配置<br>打开~/.bashrc文件：<code>sudo gedit ~/.bashrc</code><br>将以下内容写入~/.bashrc尾部：  </p><pre><code>export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda8.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}</code></pre><p>（4）测试CUDA的samples  </p><pre><code>1 cd /usr/local/cuda-8.0/samples/1_Utilities/deviceQuery  2 make  3 sudo ./deviceQuery</code></pre><p>如果显示一些关于GPU的信息，则说明安装成功。  </p><p><div align="center"><img src="https://i.imgur.com/bnOuJvJ.png" alt=""><div align="left"></div></div></p><h2 id="配置cuDNN"><a href="#配置cuDNN" class="headerlink" title="配置cuDNN"></a>配置cuDNN</h2><p>cuDNN是GPU加速计算深层神经网络的库。<br>首先去官网<code>https://developer.nvidia.com/rdp/cudnn-download</code>下载cuDNN，需要注册一个账号才能下载。下载版本号如下图：  </p><p><div align="center"><img src="https://i.imgur.com/6MwacDL.png" alt=""><div align="left"><br>下载cuDNN5.1之后进行解压：（对应自己下载的版本）<br><code>sudo tar -zxvf ./cudnn-8.0-linux-x64-v5.1.tgz</code><br>进入cuDNN5.1解压之后的include目录,在命令行进行如下操作：  </div></div></p><pre><code>cd cuda /includesudo cp cudnn.h /usr/local/cuda/include  #复制头文件</code></pre><p>再将进入lib64目录下的动态文件进行复制和链接：  </p><pre><code>cd ..cd lib64sudo cp lib* /usr/local/cuda/lib64/    #复制动态链接库cd /usr/local/cuda/lib64/sudo rm -rf libcudnn.so libcudnn.so.5    #删除原有动态文件sudo ln -s libcudnn.so.5.0.5 libcudnn.so.5  #生成软衔接sudo ln -s libcudnn.so.5 libcudnn.so      #生成软链接</code></pre><p><strong>画重点</strong><br>此处<code>sudo ln -s libcudnn.so.5.0.5 libcudnn.so.5</code>中的<code>libcudnn.so.5.0.5</code>文件需要与你电脑中<code>/usr/local/cuda/lib64/</code>文件夹中的对应，如果不对应就会在编译caffe时make all 报如下错误：（原因是cudnn链接没有弄好）</p><p><div align="center"><img src="https://i.imgur.com/9VbpthC.png" alt=""><div align="left"><br>错误如：  </div></div></p><pre><code>LD -O .build_release/lib/libcaffe.so.1.0.0/usr/bin/ld:找不到 -lcudnncollect2: error: ld returned 1 exit statusMakefile:573:recipe for target &apos;.build_release/lib/libcaffe.so.1.0.0&apos; failedMake: *** [.build_release/lib/libcaffe.so.1.0.0] Error1</code></pre><p>例如本人<code>/usr/local/cuda/lib64/</code>文件夹对应的文件为：</p><p><div align="center"><img src="https://i.imgur.com/aHQXXwE.png" alt=""><div align="left"></div></div></p><p>所以<code>sudo ln -s libcudnn.so.5.0.5 libcudnn.so.5</code>需要改为<code>sudo ln -s libcudnn.so.5.0.10 libcudnn.so.5</code>，否则会报错，谷歌百度，上都没有答案，仅此一家！  </p><h2 id="安装opencv-3-1"><a href="#安装opencv-3-1" class="headerlink" title="安装opencv 3.1"></a>安装opencv 3.1</h2><p>从官网<code>http://opencv.org/downloads.html</code>下载Opencv,并将其解压到你要安装的位置，假设解压到了<code>/home/opencv</code>。  </p><pre><code>1 unzip opencv-3.1.0.zip2 sudo cp ./opencv-3.1.0 /home3 sudo mv opencv-3.1.0 opencv</code></pre><p>安装前准备，创建编译文件夹：  </p><pre><code>cd ~/opencvmkdir buildcd build</code></pre><p>配置：</p><pre><code>1 sudo apt install cmake2 sudo cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local ..</code></pre><p>编译：</p><pre><code>sudo make -j8 </code></pre><p>-j8表示并行计算，根据自己电脑的配置进行设置，配置比较低的电脑可以将数字改小或不使用，直接输make。  </p><p>可能出现问题：  </p><p><div align="center"><img src="https://i.imgur.com/1YkArLF.png" alt=""><div align="left"><br>这是因为opecv3.0与cuda8.0不兼容导致的。解决办法：修改 ～/opencv/modules/cudalegacy/src/graphcuts.cpp文件内容，如图：</div></div></p><p><div align="center"><img src="https://i.imgur.com/gb1VeNB.png" alt=""><div align="left"></div></div></p><p>其中，<code>#if !defined (HAVE_CUDA) || defined (CUDA_DISABLER)||(CUDART_VERSION&gt;=8000)</code>是我们修改的。<br>以上只是将opencv编译成功，还没将opencv安装，需要运行下面指令进行安装：</p><pre><code>sudo make install</code></pre><h2 id="配置caffe"><a href="#配置caffe" class="headerlink" title="配置caffe"></a>配置caffe</h2><p>(1) 使用Git直接下载Caffe非常简单，或者去<code>https://github.com/BVLC/caffe</code>下载。由于我习惯去github上找代码，所以就直接去下载的源码。下载完成后，会在家目录下的下载里找到caffe-master.zip，用unzip命令解压到家目录下，然后重命名为caffe.<br>(2) 因为make指令只能<code>make Makefile.config</code>文件，而<code>Makefile.config.example</code>是caffe给出的makefile例子，因此，首先将Makefile.config.example的内容复制到Makefile.config：   </p><pre><code>sudo cp Makefile.config.example Makefile.config</code></pre><p>(3) 打开并修改配置文件：<br><strong>sudo gedit Makefile.config #打开Makefile.config文件 根据个人情况修改文件：</strong><br>a.若使用cudnn，则将<code>#USE_CUDNN := 1</code>修改成：<code>USE_CUDNN := 1</code>;<br>b.若使用的opencv版本是3的，则将<code>#OPENCV_VERSION := 3</code>修改为：<code>OPENCV_VERSION :=3</code>;<br>c.若要使用python来编写layer，则将<code>#WITH_PYTHON_LAYER := 1</code> 修改为 <code>WITH_PYTHON_LAYER := 1</code>;<br>d.重要的一项 :<br>将 # Whatever else you find you need goes here. 下面的</p><pre><code>1 INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include2 LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib </code></pre><p>修改为：</p><pre><code>1 INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial2 LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial       </code></pre><p>这是因为ubuntu16.04的文件包含位置发生了变化，尤其是需要用到的hdf5的位置，所以需要更改这一路径。<br>（4）修改makefile文件<br>打开makefile文件，做如下修改：<br>将：  </p><pre><code>NVCCFLAGS +=-ccbin=$(CXX) -Xcompiler-fPIC $(COMMON_FLAGS)  </code></pre><p>替换为：</p><pre><code>NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)</code></pre><p>(5) 编辑/usr/local/cuda/include/host_config.h 将其中的第115行（或119行）注释掉：<br>将  </p><pre><code>#error-- unsupported GNU version! gcc versions later than 4.9 are not supported!改为//#error-- unsupported GNU version! gcc versions later than 4.9 are not supported!</code></pre><p>(6) 编译<br>make all -j8 #-j根据自己电脑配置决定 编译过程中可能会出现如下错误：<br><strong>错误内容1：”fatal error: hdf5.h: 没有那个文件或目录”</strong><br>解决办法：<br><strong>step1:</strong>   在Makefile.config文件的第85行，添加/usr/include/hdf5/serial/ 到 INCLUDE_DIRS，也就是把下面第一行代码改为第二行代码。<br>将：</p><pre><code>INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include</code></pre><p>替换为：</p><pre><code>INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial/</code></pre><p><strong>stept2:</strong>  在Makefile文件的第173行，把 hdf5_hl 和hdf5修改为hdf5_serial_hl 和 hdf5_serial，也就是把下面第一行代码改为第二行代码。<br>将：  </p><pre><code>LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_hl hdf5</code></pre><p>改为： </p><pre><code>LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_serial_hl hdf5_serial  </code></pre><p><strong>错误内容2：</strong><br>“libcudnn.so.5 cannot open shared object file: No such file or directory”<br>解决办法是将一些文件复制到/usr/local/lib文件夹下：<br><strong>注意自己CUDA的版本号！</strong></p><pre><code>1 sudo cp /usr/local/cuda-8.0/lib64/libcudart.so.8.0 /usr/local/lib/libcudart.so.8.0 &amp;&amp; sudo ldconfig2 sudo cp /usr/local/cuda-8.0/lib64/libcublas.so.8.0 /usr/local/lib/libcublas.so.8.0 &amp;&amp; sudo ldconfig3 sudo cp /usr/local/cuda-8.0/lib64/libcurand.so.8.0 /usr/local/lib/libcurand.so.8.0 &amp;&amp; sudo ldconfig4 sudo cp /usr/local/cuda-8.0/lib64/libcudnn.so.5 /usr/local/lib/libcudnn.so.5 &amp;&amp; sudo ldconfig</code></pre><p>（8）测试</p><pre><code>make testmake runtest</code></pre><p>如果运行之后出现下图，说明caffe配置成功。</p><p><div align="center"><img src="https://i.imgur.com/8UHrKlr.png" alt=""><div align="left"><br>到此caffe配置完毕！  </div></div></p><h2 id="MNIST数据集测试"><a href="#MNIST数据集测试" class="headerlink" title="MNIST数据集测试"></a>MNIST数据集测试</h2><p>配置caffe完成后，我们可以利用MNIST数据集对caffe进行测试，过程如下：<br><strong>1.将终端定位到Caffe根目录</strong><br>cd ~/caffe  </p><p><strong>2.下载MNIST数据库并解压缩</strong><br>./data/mnist/get_mnist.sh</p><p><strong>3.将其转换成Lmdb数据库格式</strong><br>./examples/mnist/create_mnist.sh</p><p><strong>4.训练网络</strong><br>./examples/mnist/train_lenet.sh<br>训练的时候可以看到损失与精度数值，如下图：</p><p><div align="center"><img src="https://i.imgur.com/laVqx8Q.png" alt=""><div align="left"></div></div></p><p><strong>到此OK，大家加油～</strong></p>]]></content>
    
    <summary type="html">
    
      caffe配置GPU
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="caffe" scheme="http://yoursite.com/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>图像分类 *K-最近邻算法*</title>
    <link href="http://yoursite.com/2018/04/09/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%AC%94%E8%AE%B0cs231n1/"/>
    <id>http://yoursite.com/2018/04/09/图像分类笔记cs231n1/</id>
    <published>2018-04-09T04:49:26.541Z</published>
    <updated>2018-04-25T03:41:21.512Z</updated>
    
    <content type="html"><![CDATA[<h1 id="图像分类笔记"><a href="#图像分类笔记" class="headerlink" title="图像分类笔记"></a>图像分类笔记</h1><p>  <strong>本内容为学习斯坦福课程CS231n 2017的课后笔记记录</strong><br><a id="more"></a><br>    原文链接地址：<a href="https://blog.csdn.net/nnnnnnnnnnnny/article/details/54577123" target="_blank" rel="noopener">https://blog.csdn.net/nnnnnnnnnnnny/article/details/54577123</a><br>&emsp;&emsp;例子：以上图为例，图像分类模型读取该图片，并生成该图片属于集合 {cat, dog, hat, mug}中各个标签的概率。需要注意的是，对于计算机来说，图像是一个由数字组成的巨大的3维数组。在这个例子中，猫的图像大小是宽248像素，高400像素，有3个颜色通道，分别是红、绿和蓝（简称RGB）。如此，该图像就包含了248X400X3=297600个数字，每个数字都是在范围0-255之间的整型，其中0表示全黑，255表示全白。我们的任务就是把这些上百万的数字变成一个简单的标签，比如“猫”。</p><p><div align="center"><img src="https://i.imgur.com/8hIpE9i.jpg" alt=""><div align="left"><br>&emsp;&emsp;图像分类的任务，就是对于一个给定的图像，预测它属于的那个分类标签（或者给出属于一系列不同标签的可能性）。图像是3维数组，数组元素是取值范围从0到255的整数。数组的尺寸是宽度x高度x3，其中这个3代表的是红、绿和蓝3个颜色通道。<br>困难和挑战：对于人来说，识别出一个像“猫”一样视觉概念是简单至极的，然而从计算机视觉算法的角度来看就值得深思了。我们在下面列举了计算机视觉算法在图像识别方面遇到的一些困难，要记住图像是以3维数组来表示的，数组中的元素是亮度值。<br>&emsp;&emsp;<strong>•视角变化（Viewpoint variation）：</strong>同一个物体，摄像机可以从多个角度来展现。<br>&emsp;&emsp;<strong>•大小变化（Scale variation）：</strong>物体可视的大小通常是会变化的（不仅是在图片中，在真实世界中大小也是变化的）。<br>&emsp;&emsp;<strong>•形变（Deformation）：</strong>很多东西的形状并非一成不变，会有很大变化。<br>&emsp;&emsp;<strong>•遮挡（Occlusion）：</strong>目标物体可能被挡住。有时候只有物体的一小部分（可以小到几个像素）是可见的。<br>&emsp;&emsp;<strong>光照条件（Illumination conditions）：</strong>在像素层面上，光照的影响非常大。<br>&emsp;&emsp;<strong>背景干扰（Background clutter）：</strong>物体可能混入背景之中，使之难以被辨认。<br>&emsp;&emsp;<strong>类内差异（Intra-class variation）：</strong>一类物体的个体之间的外形差异很大，比如椅子。这一类物体有许多不同的对象，每个都有自己的外形。<br>&emsp;&emsp;面对以上所有变化及其组合，好的图像分类模型能够在维持分类结论稳定的同时，保持对类间差异足够敏感。  </div></div></p><p><div align="center"><img src="https://i.imgur.com/xdisd9U.jpg" alt=""><div align="left">  </div></div></p><h2 id="数据驱动方法："><a href="#数据驱动方法：" class="headerlink" title="数据驱动方法："></a>数据驱动方法：</h2><p>&emsp;&emsp;如何写一个图像分类的算法呢？这和写个排序算法可是大不一样。怎么写一个从图像中认出猫的算法？搞不清楚。因此，与其在代码中直接写明各类物体到底看起来是什么样的，倒不如说我们采取的方法和教小孩儿看图识物类似：给计算机很多数据，然后实现学习算法，让计算机学习到每个类的外形。这种方法，就是数据驱动方法。既然该方法的第一步就是收集已经做好分类标注的图片来作为训练集，那么下面就看看数据库到底长什么样：</p><p><div align="center"><img src="https://i.imgur.com/fBmn0wi.jpg" alt=""><div align="left"><br>&emsp;&emsp;一个有4个视觉分类的训练集。在实际中，我们可能有上千的分类，每个分类都有成千上万的图像。    </div></div></p><h2 id="图像分类流程："><a href="#图像分类流程：" class="headerlink" title="图像分类流程："></a>图像分类流程：</h2><p>&emsp;&emsp;在课程视频中已经学习过，图像分类就是输入一个元素为像素值的数组，然后给它分配一个分类标签。完整流程如下：<br>&emsp;&emsp;<strong>•输入：</strong>输入是包含N个图像的集合，每个图像的标签是K种分类标签中的一种。这个集合称为训练集。<br>&emsp;&emsp;<strong>•学习：</strong> 这一步的任务是使用训练集来学习每个类到底长什么样。一般该步骤叫做训练分类器或者学习一个模型。<br>&emsp;&emsp;<strong>•评价：</strong>让分类器来预测它未曾见过的图像的分类标签，并以此来评价分类器的质量。我们会把分类器预测的标签和图像真正的分类标签对比。毫无疑问，分类器预测的分类标签和图像真正的分类标签如果一致，那就是好事，这样的情况越多越好。  </p><h2 id="Nearest-Neighbor分类器"><a href="#Nearest-Neighbor分类器" class="headerlink" title="Nearest Neighbor分类器"></a>Nearest Neighbor分类器</h2><p>作为课程介绍的第一个方法，我们来实现一个Nearest Neighbor分类器。虽然这个分类器和卷积神经网络没有任何关系，实际中也极少使用，但通过实现它，可以让读者对于解决图像分类问题的方法有个基本的认识。<br><strong>图像分类数据集：CIFAR-10。</strong>一个非常流行的图像分类数据集是CIFAR-10。这个数据集包含了60000张32X32的小图像。每张图像都有10种分类标签中的一种。这60000张图像被分为包含50000张图像的训练集和包含10000张图像的测试集。在下图中你可以看见10个类的10张随机图片。  </p><p><div align="center"><img src="https://i.imgur.com/dOUtNa6.jpg" alt="">  <div align="left"><br><strong>左边：</strong>从CIFAR-10数据库来的样本图像。右边：第一列是测试图像，然后第一列的每个测试图像右边是使用Nearest Neighbor算法，根据像素差异，从训练集中选出的10张最类似的图片。<br>&emsp;&emsp;假设现在我们有CIFAR-10的50000张图片（每种分类5000张）作为训练集，我们希望将余下的10000作为测试集并给他们打上标签。Nearest Neighbor算法将会拿着测试图片和训练集中每一张图片去比较，然后将它认为最相似的那个训练集图片的标签赋给这张测试图片。上面右边的图片就展示了这样的结果。请注意上面10个分类中，只有3个是准确的。比如第8行中，马头被分类为一个红色的跑车，原因在于红色跑车的黑色背景非常强烈，所以这匹马就被错误分类为跑车了。<br>&emsp;&emsp;那么具体如何比较两张图片呢？在本例中，就是比较32x32x3的像素块。最简单的方法就是逐个像素比较，最后将差异值全部加起来。换句话说，就是将两张图片先转化为两个向量I1和I2，然后计算他们的 <strong>L1距离：</strong>  </div></div></p><p><div align="center"><img src="https://i.imgur.com/xI35yfu.png" alt=""> <div align="left"><br>这里的求和是针对所有的像素。下面是整个比较流程的图例：</div></div></p><p><div align="center"><img src="https://i.imgur.com/pncs90L.jpg" alt=""> <div align="left"></div></div></p><p>以图片中的一个颜色通道为例来进行说明。两张图片使用L1距离来进行比较。逐个像素求差值，然后将所有差值加起来得到一个数值。如果两张图片一模一样，那么L1距离为0，但是如果两张图片很是不同，那L1值将会非常大。</p><p><strong>距离选择：</strong>计算向量间的距离有很多种方法，另一个常用的方法是<strong>L2距离</strong>，从几何学的角度，可以理解为它在计算两个向量间的欧式距离。L2距离的公式如下：  </p><p><div align="center">!<img src="https://i.imgur.com/OGU8ocz.png" alt=""> <div align="left"><br>换句话说，我们依旧是在计算像素间的差值，只是先求其平方，然后把这些平方全部加起来，最后对这个和开方。<br><strong>L1和L2比较:</strong>比较这两个度量方式是挺有意思的。在面对两个向量之间的差异时，L2比L1更加不能容忍这些差异。也就是说，相对于1个巨大的差异，L2距离更倾向于接受多个中等程度的差异。L1和L2都是在p-norm常用的特殊形式。 </div></div></p><p><div align="center"><img src="https://i.imgur.com/GHlGUnq.png" alt=""><div align="left"> </div></div></p><h2 id="k-Nearest-Neighbor分类器"><a href="#k-Nearest-Neighbor分类器" class="headerlink" title="k-Nearest Neighbor分类器"></a>k-Nearest Neighbor分类器</h2><p>你可能注意到了，为什么只用最相似的1张图片的标签来作为测试图像的标签呢？这不是很奇怪吗！是的，使用k-Nearest Neighbor分类器就能做得更好。它的思想很简单：与其只找最相近的那1个图片的标签，我们找最相似的k个图片的标签，然后让他们针对测试图片进行投票，最后把票数最高的标签作为对测试图片的预测。所以当k=1的时候，<strong>k-Nearest Neighbor分类器</strong>就是Nearest Neighbor分类器。从直观感受上就可以看到，更高的k值可以让分类的效果更平滑，使得分类器对于异常值更有抵抗力。  </p><h2 id="用于超参数调优的验证集"><a href="#用于超参数调优的验证集" class="headerlink" title="用于超参数调优的验证集"></a>用于超参数调优的验证集</h2><p>k-NN分类器需要设定k值，那么选择哪个k值最合适的呢？我们可以选择不同的距离函数，比如L1范数和L2范数等，那么选哪个好？还有不少选择我们甚至连考虑都没有考虑到（比如：点积）。所有这些选择，被称为超参数（hyperparameter）。在基于数据进行学习的机器学习算法设计中，超参数是很常见的。一般说来，这些超参数具体怎么设置或取值并不是显而易见的。  </p><p>你可能会建议尝试不同的值，看哪个值表现最好就选哪个。好主意！我们就是这么做的，但这样做的时候要非常细心。特别注意：<strong>决不能使用测试集来进行调优</strong>。当你在设计机器学习算法的时候，应该把测试集看做非常珍贵的资源，不到最后一步，绝不使用它。如果你使用测试集来调优，而且算法看起来效果不错，那么真正的危险在于：算法实际部署后，性能可能会远低于预期。这种情况，称之为算法对测试集过拟合。从另一个角度来说，如果使用测试集来调优，实际上就是把测试集当做训练集，由测试集训练出来的算法再跑测试集，自然性能看起来会很好。这其实是过于乐观了，实际部署起来效果就会差很多。所以，最终测试的时候再使用测试集，可以很好地近似度量你所设计的分类器的泛化性能（在接下来的课程中会有很多关于泛化性能的讨论）。  </p><p><strong>测试数据集只使用一次，即在训练完成后评价最终的模型时使用。</strong>  </p><p>好在我们有不用测试集调优的方法。其思路是：从训练集中取出一部分数据用来调优，我们称之为<strong>验证集（validation set）</strong>。以CIFAR-10为例，我们可以用49000个图像作为训练集，用1000个图像作为验证集。验证集其实就是作为假的测试集来调优。</p><p>程序结束后，我们会作图分析出哪个k值表现最好，然后用这个k值来跑真正的测试集，并作出对算法的评价。</p><p><strong>把训练集分成训练集和验证集。使用验证集来对所有超参数调优。最后只在测试集上跑一次并报告结果。</strong></p><h2 id="超参数调优注意问题"><a href="#超参数调优注意问题" class="headerlink" title="超参数调优注意问题"></a>超参数调优注意问题</h2><p><div align="center"><img src="https://i.imgur.com/uA2tX9C.png" alt=""><div align="left"></div></div></p><p><strong>1.选择能对你训练集给出最高准确率，表现最佳的超参数</strong><br>&emsp;&emsp;<strong>千万不要这么做</strong><br>&emsp;&emsp;例如在之前的k-最近邻分类算法中，假设k=1我们总能完美分类训练集数据，所以如果我们采用这一策略，总是选择k=1，但是正如之前案例所见的，在实践中，让k取更大的值会在训练集中分错个别数据，但是对于在训练集中，未出现过的数据分类性能更佳。<br>&emsp;&emsp;我们关心的不是要尽可能拟合训练集，而是要让我们的分类器，我们的方法在训练集以外的未知数据上表现更好。 </p><p><strong>2.把所有的数据分成两部分，一部分是训练集，一部分是测试集，然后在训练集上用不同的超参数来训练算法，然后将训练好的分类器，用在测试集上，再选择一组在测试集上表现最好的超参数。</strong><br>&emsp;&emsp;<strong>错误做法</strong><br>&emsp;&emsp;因为同样的机器学习系统的目的，是让我们了解算法表现究竟如何，所以测试集的目的是给了我们一种预估的方法，即在没有遇到的数据上算法表现将会如何，如果采用这种用不同的超参数，训练不同算法的策略，然后选择在测试集上表现最好的超参数，那么很可能我们选择了，一组超参数，只是让我们的算法在这组测试集上表现良好，但是这组测试集的表现无法代表在全新的未见过的数据上的表现。 </p><p><strong>3.更常见的做法就是将数据，分为不同的三组，大部分数据作为训练集（train set），然后建立一个验证集（validation set），一个测试集（test set），我们通常所做的就是，在训练集上用不同的超参数来训练算法，在验证集上进行评估，然后用一组超参数，选择在验证集上表现最好的，然后当完成了这些步骤以后，你也完成了所有的调试，所有都完成了，然后把这组在验证集上表现最佳的分类器拿出来，在测试集上跑一跑，这才是你写到论文中的数据，也是你要写到报告中的数据，这个数据才告诉你，你的算法在未见的新数据上表现如何，非常非常重要的一点就是，必须分割验证集和测试集，要保证测试集收到严格的控制。</strong>   </p><p><strong>4.超参数的另一个方法就是交叉验证，这个在小数据集中更常用一些，在深度学习中不那么常用。因为：在深度学习中，当我们训练大型模型时，训练本身非常消耗计算能力，因此这些方法实际不常用。</strong> </p><p><strong>5.训练集和验证集的区别：</strong><br>&emsp;&emsp;如果你想一想k-最近邻分类算法（KNN），那么训练集就是一堆贴上标签的图片，我们记下标签，要给图像分类，我们会将图片与训练集的每一个元素比较，然后将与训练点最接近点的标签作为结果，我们的算法会记住训练集中的所有样本，然后我们会把验证集中的每个元素与训练集中的每个元素比较，将它为依据判定分类器的准确率，在验证集上表现如何，这就是验证集和训练集的区别，你的算法可以看到训练集中的各个标签，但是在验证集中，你的算法不能直接看到他们的标签，我们只是用验证集中的标签，来检查我们算法的表现。  </p><p><strong>6.关于测试集能不能很好地代表真实世界中的数据？</strong><br>&emsp;&emsp;我们背后的统计学假设就是，你的数据都互相独立，服从同一分布，这样你数据上所有的点都来自同一个概率分布，当然在现实中不可能总是这样的情况，你可能碰到一些其他的情况，也就是你的测试集代表性，不佳，不能很好地反映真实世界。这一问题就是数据集的创建者和数据集管理者需要好好思考的。</p><h2 id="交叉验证："><a href="#交叉验证：" class="headerlink" title="交叉验证："></a>交叉验证：</h2><p>&emsp;&emsp;有时候，训练集数量较小（因此验证集的数量更小），人们会使用一种被称为交叉验证的方法，这种方法更加复杂些。还是用刚才的例子，如果是交叉验证集，我们就不是取1000个图像，而是将训练集平均分成5份，其中4份用来训练，1份用来验证。然后我们循环着取其中4份来训练，其中1份来验证，最后取所有5次验证结果的平均值作为算法验证结果。</p><p><strong>实际应用。在实际情况下，人们不是很喜欢用交叉验证，主要是因为它会耗费较多的计算资源。一般直接把训练集按照50%-90%的比例分成训练集和验证集。但这也是根据具体情况来定的：如果超参数数量多，你可能就想用更大的验证集，而验证集的数量不够，那么最好还是用交叉验证吧。至于分成几份比较好，一般都是分成3、5和10份。</strong></p><p><div align="center"><img src="https://i.imgur.com/6sXrGbH.jpg" alt=""> <div align="left"> </div></div></p><p>常用的数据分割模式。给出训练集和测试集后，训练集一般会被均分。这里是分成5份。前面4份用来训练，黄色那份用作验证集调优。如果采取交叉验证，那就各份轮流作为验证集。最后模型训练完毕，超参数都定好了，让模型跑一次（而且只跑一次）测试集，以此测试结果评价算法。</p><h2 id="Nearest-Neighbor分类器的优劣"><a href="#Nearest-Neighbor分类器的优劣" class="headerlink" title="Nearest Neighbor分类器的优劣"></a>Nearest Neighbor分类器的优劣</h2><p>现在对Nearest Neighbor分类器的优缺点进行思考。首先，Nearest Neighbor分类器易于理解，实现简单。其次，算法的训练不需要花时间，因为其训练过程只是将训练集数据存储起来。然而测试要花费大量时间计算，因为每个测试图像需要和所有存储的训练图像进行比较，这显然是一个缺点。在实际应用中，我们关注测试效率远远高于训练效率。其实，我们后续要学习的卷积神经网络在这个权衡上走到了另一个极端：虽然训练花费很多时间，但是一旦训练完成，对新的测试数据进行分类非常快。这样的模式就符合实际使用需求。  </p><p>Nearest Neighbor分类器的计算复杂度研究是一个活跃的研究领域，若干Approximate Nearest Neighbor (ANN)算法和库的使用可以提升Nearest Neighbor分类器在数据上的计算速度（比如：FLANN）。这些算法可以在准确率和时空复杂度之间进行权衡，并通常依赖一个预处理/索引过程，这个过程中一般包含kd树的创建和k-means算法的运用。</p><p>Nearest Neighbor分类器在某些特定情况（比如数据维度较低）下，可能是不错的选择。但是在实际的图像分类工作中，很少使用。因为图像都是高维度数据（他们通常包含很多像素），而高维度向量之间的距离通常是反直觉的。下面的图片展示了基于像素的相似和基于感官的相似是有很大不同的：</p><p><div align="center"><img src="https://i.imgur.com/6NuH1he.jpg" alt=""> <div align="left"></div></div></p><p>在高维度数据上，基于像素的的距离和感官上的非常不同。上图中，右边3张图片和左边第1张原始图片的L2距离是一样的。很显然，基于像素比较的相似和感官上以及语义上的相似是不同的。</p><p>这里还有个视觉化证据，可以证明使用像素差异来比较图像是不够的。z这是一个叫做t-SNE的可视化技术，它将CIFAR-10中的图片按照二维方式排布，这样能很好展示图片之间的像素差异值。在这张图片中，排列相邻的图片L2距离就小。</p><p><div align="center"><img src="https://i.imgur.com/X9WkGrp.jpg" alt=""><div align="left">  </div></div></p><p>上图使用t-SNE的可视化技术将CIFAR-10的图片进行了二维排列。排列相近的图片L2距离小。可以看出，图片的排列是被背景主导而不是图片语义内容本身主导。</p><p>具体说来，这些图片的排布更像是一种颜色分布函数，或者说是基于背景的，而不是图片的语义主体。比如，狗的图片可能和青蛙的图片非常接近，这是因为两张图片都是白色背景。从理想效果上来说，我们肯定是希望同类的图片能够聚集在一起，而不被背景或其他不相关因素干扰。为了达到这个目的，我们不能止步于原始像素比较，得继续前进。</p><h1 id="小结：实际应用k-NN"><a href="#小结：实际应用k-NN" class="headerlink" title="小结：实际应用k-NN"></a>小结：实际应用k-NN</h1><p>如果你希望将k-NN分类器用到实处（最好别用到图像上，若是仅仅作为练手还可以接受），那么可以按照以下流程：<br>&emsp;&emsp;<strong>1.预处理你的数据：</strong>对你数据中的特征进行归一化（normalize），让其具有零平均值（zero mean）和单位方差（unit variance）。在后面的小节我们会讨论这些细节。本小节不讨论，是因为图像中的像素都是同质的，不会表现出较大的差异分布，也就不需要标准化处理了。<br>&emsp;&emsp;<strong>2.如果数据是高维数据，</strong>考虑使用降维方法，比如PCA(wiki ref, CS229ref, blog ref)或随机投影。<br>&emsp;&emsp;<strong>3.将数据随机分入训练集和验证集。</strong>按照一般规律，70%-90% 数据作为训练集。这个比例根据算法中有多少超参数，以及这些超参数对于算法的预期影响来决定。如果需要预测的超参数很多，那么就应该使用更大的验证集来有效地估计它们。如果担心验证集数量不够，那么就尝试交叉验证方法。如果计算资源足够，使用交叉验证总是更加安全的（份数越多，效果越好，也更耗费计算资源）。<br>&emsp;&emsp;<strong>4.在验证集上调优</strong>，尝试足够多的k值，尝试L1和L2两种范数计算方式。<br>&emsp;&emsp;<strong>5.如果分类器跑得太慢</strong> ，尝试使用Approximate Nearest Neighbor库（比如FLANN）来加速这个过程，其代价是降低一些准确率。<br>&emsp;&emsp;<strong>6.对最优的超参数做记录。</strong>记录最优参数后，是否应该让使用最优参数的算法在完整的训练集上运行并再次训练呢？因为如果把验证集重新放回到训练集中（自然训练集的数据量就又变大了），有可能最优参数又会有所变化。在实践中，不要这样做。千万不要在最终的分类器中使用验证集数据，这样做会破坏对于最优参数的估计。直接使用测试集来测试用最优参数设置好的最优模型，得到测试集数据的分类准确率，并以此作为你的kNN分类器在该数据上的性能表现。</p>]]></content>
    
    <summary type="html">
    
      图像分类笔记
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
</feed>
